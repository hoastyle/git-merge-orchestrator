import subprocess
import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict
import re

class GitMergeTool:
    def __init__(self, source_branch, target_branch, repo_path=".", max_files_per_group=5):
        self.source_branch = source_branch
        self.target_branch = target_branch
        self.repo_path = Path(repo_path)
        self.max_files_per_group = max_files_per_group
        self.integration_branch = f"integration-{source_branch.replace('/', '-')}-{target_branch.replace('/', '-')}"
        self.work_dir = self.repo_path / ".merge_work"
        self.work_dir.mkdir(exist_ok=True)

        # ç¼“å­˜æ´»è·ƒç”¨æˆ·åˆ—è¡¨
        self._active_contributors_cache = None
        self._all_contributors_cache = None

    def _get_display_width(self, text):
        """è®¡ç®—æ˜¾ç¤ºå®½åº¦ï¼Œè€ƒè™‘ä¸­æ–‡å­—ç¬¦"""
        width = 0
        for char in str(text):
            if ord(char) > 127:  # ä¸­æ–‡å­—ç¬¦
                width += 2
            else:  # è‹±æ–‡å­—ç¬¦
                width += 1
        return width

    def _format_table_cell(self, text, width, align='left'):
        """æ ¼å¼åŒ–è¡¨æ ¼å•å…ƒæ ¼ï¼Œç¡®ä¿å¯¹é½"""
        text_str = str(text)
        display_width = self._get_display_width(text_str)
        padding = width - display_width

        if padding <= 0:
            return text_str[:width]

        if align == 'left':
            return text_str + ' ' * padding
        elif align == 'right':
            return ' ' * padding + text_str
        elif align == 'center':
            left_pad = padding // 2
            right_pad = padding - left_pad
            return ' ' * left_pad + text_str + ' ' * right_pad

        return text_str

    def _print_table_separator(self, widths):
        """æ‰“å°è¡¨æ ¼åˆ†éš”çº¿"""
        total_width = sum(widths) + len(widths) - 1
        print('-' * total_width)

    def _print_table_header(self, headers, widths, aligns=None):
        """æ‰“å°è¡¨æ ¼æ ‡é¢˜è¡Œ"""
        if aligns is None:
            aligns = ['left'] * len(headers)

        row = []
        for i, (header, width, align) in enumerate(zip(headers, widths, aligns)):
            row.append(self._format_table_cell(header, width, align))

        print(' '.join(row))
        self._print_table_separator(widths)

    def _print_table_row(self, values, widths, aligns=None):
        """æ‰“å°è¡¨æ ¼æ•°æ®è¡Œ"""
        if aligns is None:
            aligns = ['left'] * len(values)

        row = []
        for i, (value, width, align) in enumerate(zip(values, widths, aligns)):
            row.append(self._format_table_cell(value, width, align))

        print(' '.join(row))

    def run_git_command(self, cmd):
        """æ‰§è¡Œgitå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                cmd, shell=True, cwd=self.repo_path,
                capture_output=True, text=True, check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            print(f"Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {cmd}")
            print(f"é”™è¯¯: {e.stderr}")
            return None

    def get_active_contributors(self, months=3):
        """è·å–è¿‘Nä¸ªæœˆæœ‰æäº¤çš„æ´»è·ƒè´¡çŒ®è€…åˆ—è¡¨"""
        if self._active_contributors_cache is not None:
            return self._active_contributors_cache

        print(f"ğŸ” æ­£åœ¨åˆ†æè¿‘{months}ä¸ªæœˆçš„æ´»è·ƒè´¡çŒ®è€…...")
        cutoff_date = (datetime.now() - timedelta(days=months * 30)).strftime('%Y-%m-%d')

        cmd = f'git log --since="{cutoff_date}" --format="%an" --all'
        result = self.run_git_command(cmd)

        active_contributors = set()
        if result:
            for author in result.split('\n'):
                if author.strip():
                    active_contributors.add(author.strip())

        self._active_contributors_cache = active_contributors
        print(f"ğŸ“Š å‘ç° {len(active_contributors)} ä½è¿‘{months}ä¸ªæœˆæ´»è·ƒçš„è´¡çŒ®è€…")
        return active_contributors

    def get_all_contributors(self):
        """è·å–æ‰€æœ‰å†å²è´¡çŒ®è€…"""
        if self._all_contributors_cache is not None:
            return self._all_contributors_cache

        cmd = 'git log --format="%an" --all'
        result = self.run_git_command(cmd)

        all_contributors = set()
        if result:
            for author in result.split('\n'):
                if author.strip():
                    all_contributors.add(author.strip())

        self._all_contributors_cache = all_contributors
        return all_contributors

    def analyze_directory_contributors(self, directory_path, include_recent=True):
        """åˆ†æç›®å½•çº§åˆ«çš„ä¸»è¦è´¡çŒ®è€…"""
        try:
            contributors = {}

            # è·å–ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶çš„è´¡çŒ®è€…ä¿¡æ¯
            if include_recent:
                one_year_ago = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
                recent_cmd = f'git log --follow --since="{one_year_ago}" --format="%an" -- "{directory_path}"'
                recent_result = self.run_git_command(recent_cmd)

                if recent_result:
                    recent_authors = recent_result.split('\n')
                    recent_author_counts = {}
                    for author in recent_authors:
                        if author.strip():
                            recent_author_counts[author] = recent_author_counts.get(author, 0) + 1

                    for author, count in recent_author_counts.items():
                        contributors[author] = {
                            'total_commits': count,
                            'recent_commits': count,
                            'score': count * 3
                        }

            # è·å–æ€»ä½“è´¡çŒ®ç»Ÿè®¡
            cmd = f'git log --follow --format="%an" -- "{directory_path}"'
            total_result = self.run_git_command(cmd)

            if total_result:
                authors = total_result.split('\n')
                author_counts = {}
                for author in authors:
                    if author.strip():
                        author_counts[author] = author_counts.get(author, 0) + 1

                for author, count in author_counts.items():
                    if author in contributors:
                        contributors[author]['total_commits'] = count
                        contributors[author]['score'] = contributors[author]['recent_commits'] * 3 + count
                    else:
                        contributors[author] = {
                            'total_commits': count,
                            'recent_commits': 0,
                            'score': count
                        }

            return contributors
        except Exception as e:
            print(f"åˆ†æç›®å½• {directory_path} æ—¶å‡ºé”™: {e}")
            return {}

    def find_fallback_assignee(self, file_paths, active_contributors):
        """ä¸ºæœªåˆ†é…çš„ç»„å¯»æ‰¾å¤‡é€‰è´Ÿè´£äºº"""
        print(f"ğŸ” æ­£åœ¨ä¸ºæœªåˆ†é…ç»„å¯»æ‰¾å¤‡é€‰è´Ÿè´£äºº...")

        # å°è¯•ä»æ–‡ä»¶è·¯å¾„å‘ä¸ŠæŸ¥æ‰¾ç›®å½•è´¡çŒ®è€…
        directories_to_check = set()

        for file_path in file_paths:
            path_parts = file_path.split('/')
            # æ£€æŸ¥å„çº§çˆ¶ç›®å½•
            for i in range(len(path_parts) - 1, 0, -1):
                parent_dir = '/'.join(path_parts[:i])
                if parent_dir:
                    directories_to_check.add(parent_dir)

        # æŒ‰ç›®å½•å±‚çº§æ’åºï¼Œä¼˜å…ˆæ£€æŸ¥æ›´å…·ä½“çš„ç›®å½•
        sorted_dirs = sorted(directories_to_check, key=lambda x: x.count('/'), reverse=True)

        for directory in sorted_dirs:
            print(f"  æ£€æŸ¥ç›®å½•: {directory}")
            dir_contributors = self.analyze_directory_contributors(directory)

            if dir_contributors:
                # æ‰¾åˆ°æ´»è·ƒçš„è´¡çŒ®è€…
                active_dir_contributors = {
                    author: stats for author, stats in dir_contributors.items()
                    if author in active_contributors
                }

                if active_dir_contributors:
                    # è¿”å›è¯„åˆ†æœ€é«˜çš„æ´»è·ƒè´¡çŒ®è€…
                    best_contributor = max(active_dir_contributors.items(), key=lambda x: x[1]['score'])
                    print(f"  âœ… åœ¨ç›®å½• {directory} æ‰¾åˆ°å€™é€‰äºº: {best_contributor[0]} (å¾—åˆ†: {best_contributor[1]['score']})")
                    return best_contributor[0], best_contributor[1], directory

        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œæ£€æŸ¥æ ¹ç›®å½•
        print("  æ£€æŸ¥æ ¹ç›®å½•...")
        root_contributors = self.analyze_directory_contributors(".")
        if root_contributors:
            active_root_contributors = {
                author: stats for author, stats in root_contributors.items()
                if author in active_contributors
            }

            if active_root_contributors:
                best_contributor = max(active_root_contributors.items(), key=lambda x: x[1]['score'])
                print(f"  âœ… åœ¨æ ¹ç›®å½•æ‰¾åˆ°å€™é€‰äºº: {best_contributor[0]} (å¾—åˆ†: {best_contributor[1]['score']})")
                return best_contributor[0], best_contributor[1], "æ ¹ç›®å½•"

        print("  âŒ æœªæ‰¾åˆ°åˆé€‚çš„å€™é€‰äºº")
        return None, None, None

    def analyze_divergence(self):
        """åˆ†æåˆ†æ”¯åˆ†å‰æƒ…å†µ"""
        print("ğŸ” æ­£åœ¨åˆ†æåˆ†æ”¯åˆ†å‰æƒ…å†µ...")

        # è·å–åˆ†å‰ç‚¹
        merge_base = self.run_git_command(f"git merge-base {self.source_branch} {self.target_branch}")
        if merge_base:
            print(f"åˆ†å‰ç‚¹: {merge_base}")
        else:
            print("âŒ æ— æ³•ç¡®å®šåˆ†å‰ç‚¹")
            return None

        # ç»Ÿè®¡å·®å¼‚
        diff_stats = self.run_git_command(f"git diff --stat {self.source_branch} {self.target_branch}")
        if diff_stats:
            print(f"\nğŸ“Š å·®å¼‚ç»Ÿè®¡:\n{diff_stats}")

        # æ£€æŸ¥é›†æˆåˆ†æ”¯æ˜¯å¦å­˜åœ¨
        branch_exists = self.run_git_command(f"git show-ref --verify --quiet refs/heads/{self.integration_branch}")

        if branch_exists is None:
            # åˆ†æ”¯ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°åˆ†æ”¯
            self.run_git_command(f"git checkout -b {self.integration_branch} {self.target_branch}")
            print(f"âœ… å·²åˆ›å»ºé›†æˆåˆ†æ”¯: {self.integration_branch}")
        else:
            # åˆ†æ”¯å·²å­˜åœ¨ï¼Œåˆ‡æ¢åˆ°è¯¥åˆ†æ”¯
            self.run_git_command(f"git checkout {self.integration_branch}")
            print(f"âœ… å·²åˆ‡æ¢åˆ°é›†æˆåˆ†æ”¯: {self.integration_branch}")

        # é¢„è§ˆåˆå¹¶ç»“æœ
        merge_result = self.run_git_command(f"git merge --no-commit --no-ff {self.source_branch} 2>&1 || echo 'merge conflicts detected'")

        # é‡ç½®åˆå¹¶çŠ¶æ€
        self.run_git_command("git merge --abort 2>/dev/null || true")

        return {
            "merge_base": merge_base,
            "diff_stats": diff_stats,
            "merge_preview": merge_result
        }

    def iterative_group_files(self, file_paths):
        """è¿­ä»£å¼åˆ†ç»„æ–‡ä»¶ï¼Œé¿å…é€’å½’æ·±åº¦é—®é¢˜"""
        print(f"ğŸ”„ ä½¿ç”¨è¿­ä»£ç®—æ³•å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶...")

        # æŒ‰ç›®å½•å±‚æ¬¡åˆ†ææ–‡ä»¶
        path_analysis = {}
        for file_path in file_paths:
            parts = file_path.split('/')
            depth = len(parts) - 1

            if depth == 0:
                key = "root"
            else:
                key = parts[0]

            if key not in path_analysis:
                path_analysis[key] = []
            path_analysis[key].append(file_path)

        print(f"ğŸ“Š å‘ç° {len(path_analysis)} ä¸ªé¡¶çº§ç›®å½•/åˆ†ç»„")

        groups = []

        for base_path, files in path_analysis.items():
            print(f" å¤„ç† {base_path}: {len(files)} ä¸ªæ–‡ä»¶")

            if len(files) <= self.max_files_per_group:
                groups.append({
                    "name": base_path,
                    "files": files,
                    "file_count": len(files),
                    "type": "simple_group"
                })
            else:
                sub_groups = self._split_large_group(base_path, files)
                groups.extend(sub_groups)

        print(f"âœ… åˆ†ç»„å®Œæˆï¼šå…± {len(groups)} ä¸ªç»„")
        return groups

    def _split_large_group(self, base_path, files):
        """åˆ†å‰²å¤§æ–‡ä»¶ç»„ä¸ºå°ç»„"""
        groups = []

        if base_path == "root":
            return self._split_by_alphabet(base_path, files)

        # éæ ¹ç›®å½•ï¼šå…ˆæŒ‰å­ç›®å½•åˆ†ç»„
        subdir_groups = defaultdict(list)
        direct_files = []

        for file_path in files:
            if file_path.startswith(base_path + "/"):
                relative_path = file_path[len(base_path + "/"):]
                if "/" in relative_path:
                    next_dir = relative_path.split("/")[0]
                    subdir_groups[f"{base_path}/{next_dir}"].append(file_path)
                else:
                    direct_files.append(file_path)
            else:
                direct_files.append(file_path)

        # å¤„ç†ç›´æ¥æ–‡ä»¶
        if direct_files:
            if len(direct_files) <= self.max_files_per_group:
                groups.append({
                    "name": f"{base_path}/direct",
                    "files": direct_files,
                    "file_count": len(direct_files),
                    "type": "direct_files"
                })
            else:
                batch_groups = self._split_into_batches(f"{base_path}/direct", direct_files)
                groups.extend(batch_groups)

        # å¤„ç†å­ç›®å½•
        for subdir_path, subdir_files in subdir_groups.items():
            if len(subdir_files) <= self.max_files_per_group:
                groups.append({
                    "name": subdir_path,
                    "files": subdir_files,
                    "file_count": len(subdir_files),
                    "type": "subdir_group"
                })
            else:
                sub_groups = self._split_large_group(subdir_path, subdir_files)
                groups.extend(sub_groups)

        return groups

    def _split_by_alphabet(self, base_name, files):
        """æŒ‰å­—æ¯åˆ†ç»„æ–‡ä»¶"""
        alpha_groups = defaultdict(list)
        for file_path in files:
            filename = file_path.split('/')[-1]
            first_char = filename[0].lower()

            if first_char.isalpha():
                alpha_groups[first_char].append(file_path)
            elif first_char.isdigit():
                alpha_groups['0-9'].append(file_path)
            else:
                alpha_groups['other'].append(file_path)

        groups = []
        for alpha, alpha_files in alpha_groups.items():
            if len(alpha_files) <= self.max_files_per_group:
                groups.append({
                    "name": f"{base_name}-{alpha}",
                    "files": alpha_files,
                    "file_count": len(alpha_files),
                    "type": "alpha_group"
                })
            else:
                batch_groups = self._split_into_batches(f"{base_name}-{alpha}", alpha_files)
                groups.extend(batch_groups)

        return groups

    def _split_into_batches(self, base_name, files):
        """å°†æ–‡ä»¶åˆ†æ‰¹å¤„ç†"""
        groups = []
        for i in range(0, len(files), self.max_files_per_group):
            batch_files = files[i:i+self.max_files_per_group]
            batch_num = i // self.max_files_per_group + 1
            groups.append({
                "name": f"{base_name}-batch{batch_num}",
                "files": batch_files,
                "file_count": len(batch_files),
                "type": "batch_group"
            })
        return groups

    def analyze_file_contributors(self, filepath, include_recent=True):
        """åˆ†ææ–‡ä»¶çš„ä¸»è¦è´¡çŒ®è€…ï¼ˆé‡ç‚¹å…³æ³¨ä¸€å¹´å†…çš„è´¡çŒ®ï¼‰"""
        try:
            contributors = {}

            # è·å–ä¸€å¹´å†…çš„è´¡çŒ®ç»Ÿè®¡ (é‡ç‚¹)
            if include_recent:
                one_year_ago = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
                recent_cmd = f'git log --follow --since="{one_year_ago}" --format="%an" -- "{filepath}"'
                recent_result = self.run_git_command(recent_cmd)

                if recent_result:
                    recent_authors = recent_result.split('\n')
                    recent_author_counts = {}
                    for author in recent_authors:
                        if author.strip():
                            recent_author_counts[author] = recent_author_counts.get(author, 0) + 1

                    for author, count in recent_author_counts.items():
                        contributors[author] = {
                            'total_commits': count,
                            'recent_commits': count,
                            'score': count * 3
                        }

            # è·å–æ€»ä½“è´¡çŒ®ç»Ÿè®¡ (è¡¥å……)
            cmd = f'git log --follow --format="%an" -- "{filepath}"'
            total_result = self.run_git_command(cmd)

            if total_result:
                authors = total_result.split('\n')
                author_counts = {}
                for author in authors:
                    if author.strip():
                        author_counts[author] = author_counts.get(author, 0) + 1

                for author, count in author_counts.items():
                    if author in contributors:
                        contributors[author]['total_commits'] = count
                        contributors[author]['score'] = contributors[author]['recent_commits'] * 3 + count
                    else:
                        contributors[author] = {
                            'total_commits': count,
                            'recent_commits': 0,
                            'score': count
                        }

            return contributors
        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}")
            return {}

    def get_group_main_contributor(self, files):
        """è·å–æ–‡ä»¶ç»„çš„ä¸»è¦è´¡çŒ®è€…ï¼ˆé‡ç‚¹åŸºäºä¸€å¹´å†…è´¡çŒ®ï¼‰"""
        all_contributors = {}

        for file in files:
            contributors = self.analyze_file_contributors(file)
            for author, stats in contributors.items():
                if author not in all_contributors:
                    all_contributors[author] = {
                        'total_commits': 0,
                        'recent_commits': 0,
                        'score': 0,
                        'file_count': 0
                    }

                all_contributors[author]['total_commits'] += stats['total_commits']
                all_contributors[author]['recent_commits'] += stats['recent_commits']
                all_contributors[author]['score'] += stats['score']
                all_contributors[author]['file_count'] += 1

        if not all_contributors:
            return None, {}

        # è¿”å›ç»¼åˆå¾—åˆ†æœ€é«˜çš„ä½œè€…ï¼ˆé‡ç‚¹æ˜¯è¿‘æœŸè´¡çŒ®ï¼‰
        main_contributor = max(all_contributors.items(), key=lambda x: x[1]['score'])
        return main_contributor[0], all_contributors

    def create_merge_plan(self):
        """åˆ›å»ºæ™ºèƒ½åˆå¹¶è®¡åˆ’ - è¿­ä»£åˆ†ç»„ç›´è‡³æ–‡ä»¶æ•°<5ï¼Œé¿å…é€’å½’æ·±åº¦é—®é¢˜"""
        print(f"ğŸ“‹ æ­£åœ¨åˆ›å»ºæ™ºèƒ½åˆå¹¶è®¡åˆ’ï¼ˆæ¯ç»„æœ€å¤š{self.max_files_per_group}ä¸ªæ–‡ä»¶ï¼‰...")

        # è·å–æ‰€æœ‰å˜æ›´æ–‡ä»¶
        changed_files_output = self.run_git_command(f"git diff --name-only {self.source_branch} {self.target_branch}")
        if not changed_files_output:
            print("âš ï¸ æ²¡æœ‰å‘ç°æ–‡ä»¶å·®å¼‚")
            return None

        changed_files = changed_files_output.split('\n')
        changed_files = [f for f in changed_files if f.strip()]

        if not changed_files:
            print("âš ï¸ æ²¡æœ‰å‘ç°æœ‰æ•ˆçš„æ–‡ä»¶å·®å¼‚")
            return None

        print(f"ğŸ” å‘ç° {len(changed_files)} ä¸ªå˜æ›´æ–‡ä»¶ï¼Œå¼€å§‹æ™ºèƒ½åˆ†ç»„...")

        # è¿­ä»£åˆ†ç»„æ–‡ä»¶ï¼ˆé¿å…é€’å½’æ·±åº¦é—®é¢˜ï¼‰
        try:
            file_groups = self.iterative_group_files(changed_files)
        except Exception as e:
            print(f"âŒ åˆ†ç»„è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            print("ğŸ”„ å›é€€åˆ°ç®€å•æ‰¹é‡åˆ†ç»„æ¨¡å¼...")
            # å›é€€åˆ°ç®€å•åˆ†ç»„
            file_groups = []
            for i in range(0, len(changed_files), self.max_files_per_group):
                batch_files = changed_files[i:i+self.max_files_per_group]
                batch_name = f"batch-{i//self.max_files_per_group + 1:03d}"
                file_groups.append({
                    "name": batch_name,
                    "files": batch_files,
                    "file_count": len(batch_files),
                    "type": "fallback_batch"
                })

        print(f"ğŸ“Š åˆ†ç»„å®Œæˆ: {len(file_groups)} ä¸ªç»„")
        for i, group in enumerate(file_groups[:10]):
            print(f" - {group['name']}: {group['file_count']} ä¸ªæ–‡ä»¶ ({group['type']})")
        if len(file_groups) > 10:
            print(f" ... è¿˜æœ‰ {len(file_groups) - 10} ä¸ªç»„")

        # ç”Ÿæˆåˆå¹¶è®¡åˆ’
        merge_plan = {
            "created_at": datetime.now().isoformat(),
            "source_branch": self.source_branch,
            "target_branch": self.target_branch,
            "integration_branch": self.integration_branch,
            "total_files": len(changed_files),
            "total_groups": len(file_groups),
            "max_files_per_group": self.max_files_per_group,
            "groups": []
        }

        for group_info in file_groups:
            merge_plan["groups"].append({
                "name": group_info["name"],
                "files": group_info["files"],
                "file_count": group_info["file_count"],
                "group_type": group_info["type"],
                "status": "pending",
                "assignee": "",
                "conflicts": [],
                "notes": "",
                "contributors": {},
                "fallback_reason": "",
                "assignment_reason": ""  # æ–°å¢ï¼šåˆ†é…åŸå› 
            })

        # ä¿å­˜è®¡åˆ’
        plan_file = self.work_dir / "merge_plan.json"
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(merge_plan, f, indent=2, ensure_ascii=False)

        print(f"âœ… æ™ºèƒ½åˆå¹¶è®¡åˆ’å·²ä¿å­˜è‡³: {plan_file}")
        print(f"ğŸ“ å…±ç”Ÿæˆ {len(file_groups)} ä¸ªåˆ†ç»„ï¼Œå¹³å‡æ¯ç»„ {len(changed_files)/len(file_groups):.1f} ä¸ªæ–‡ä»¶")

        # æ˜¾ç¤ºåˆ†ç»„ç»Ÿè®¡
        group_types = defaultdict(int)
        for group in file_groups:
            group_types[group["type"]] += 1

        print(f"ğŸ“Š åˆ†ç»„ç±»å‹ç»Ÿè®¡:")
        for group_type, count in group_types.items():
            print(f" - {group_type}: {count} ä¸ªç»„")

        return merge_plan

    def auto_assign_tasks(self, exclude_authors=None, max_tasks_per_person=3, include_fallback=True):
        """åŸºäºä¸€å¹´å†…è´¡çŒ®åº¦è‡ªåŠ¨åˆ†é…åˆå¹¶ä»»åŠ¡ï¼Œæ”¯æŒå¤‡é€‰æ–¹æ¡ˆå’Œæ´»è·ƒåº¦è¿‡æ»¤"""
        exclude_authors = exclude_authors or []
        plan_file = self.work_dir / "merge_plan.json"

        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return None

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        print("ğŸ¤– æ­£åœ¨åŸºäºä¸€å¹´å†…è´¡çŒ®åº¦è‡ªåŠ¨åˆ†é…ä»»åŠ¡...")
        print("ğŸ’¡ è¯„åˆ†è§„åˆ™ï¼šä¸€å¹´å†…æäº¤æ•° Ã— 3 + å†å²æäº¤æ•° Ã— 1")
        print("ğŸ” è‡ªåŠ¨æ’é™¤è¿‘3ä¸ªæœˆæ— æäº¤çš„äººå‘˜")

        # è·å–æ´»è·ƒè´¡çŒ®è€…
        active_contributors = self.get_active_contributors(3)

        # è‡ªåŠ¨æ·»åŠ ä¸æ´»è·ƒçš„äººå‘˜åˆ°æ’é™¤åˆ—è¡¨
        all_contributors = self.get_all_contributors()
        inactive_contributors = all_contributors - active_contributors

        if inactive_contributors:
            print(f"ğŸš« è‡ªåŠ¨æ’é™¤è¿‘3ä¸ªæœˆæ— æäº¤çš„ {len(inactive_contributors)} ä½è´¡çŒ®è€…:")
            for contributor in sorted(list(inactive_contributors))[:5]:
                print(f"   - {contributor}")
            if len(inactive_contributors) > 5:
                print(f"   ... è¿˜æœ‰ {len(inactive_contributors) - 5} ä½")

        # åˆå¹¶æ’é™¤åˆ—è¡¨
        all_excluded = set(exclude_authors) | inactive_contributors

        assignment_count = {}
        unassigned_groups = []

        for group in plan["groups"]:
            print(f"\nåˆ†æç»„: {group['name']} ({group['file_count']} ä¸ªæ–‡ä»¶)")

            # è·å–ä¸»è¦è´¡çŒ®è€…ï¼ˆé‡ç‚¹å…³æ³¨ä¸€å¹´å†…ï¼‰
            main_contributor, all_contributors = self.get_group_main_contributor(group['files'])

            assigned = False
            assignment_reason = ""

            if main_contributor and main_contributor not in all_excluded:
                # æ£€æŸ¥è´Ÿè½½å‡è¡¡
                current_count = assignment_count.get(main_contributor, 0)
                if current_count < max_tasks_per_person:
                    group["assignee"] = main_contributor
                    assignment_count[main_contributor] = current_count + 1
                    stats = all_contributors[main_contributor]
                    assignment_reason = f"åŸºäºæ–‡ä»¶è´¡çŒ®åº¦ç›´æ¥åˆ†é… (ä¸€å¹´å†…:{stats['recent_commits']}, å†å²:{stats['total_commits']}, å¾—åˆ†:{stats['score']})"
                    print(f" âœ… åˆ†é…ç»™: {main_contributor}")
                    print(f" ä¸€å¹´å†…æäº¤: {stats['recent_commits']}, å†å²æäº¤: {stats['total_commits']}, ç»¼åˆå¾—åˆ†: {stats['score']}")
                    assigned = True
                else:
                    # æ‰¾ç¬¬äºŒåˆé€‚çš„äººé€‰
                    sorted_contributors = sorted(all_contributors.items(), key=lambda x: x[1]['score'], reverse=True)
                    for author, stats in sorted_contributors[1:]:
                        if author not in all_excluded and assignment_count.get(author, 0) < max_tasks_per_person:
                            group["assignee"] = author
                            assignment_count[author] = assignment_count.get(author, 0) + 1
                            assignment_reason = f"è´Ÿè½½å‡è¡¡åˆ†é… (åŸæ¨è{main_contributor}å·²æ»¡è´Ÿè·, ä¸€å¹´å†…:{stats['recent_commits']}, å†å²:{stats['total_commits']}, å¾—åˆ†:{stats['score']})"
                            print(f" âœ… åˆ†é…ç»™: {author}")
                            print(f" ä¸€å¹´å†…æäº¤: {stats['recent_commits']}, å†å²æäº¤: {stats['total_commits']}, ç»¼åˆå¾—åˆ†: {stats['score']}")
                            print(f" (åŸæ¨è {main_contributor} å·²æ»¡è´Ÿè·)")
                            assigned = True
                            break

            # å¦‚æœè¿˜æœªåˆ†é…ä¸”å¯ç”¨å¤‡é€‰æ–¹æ¡ˆï¼Œå°è¯•ç›®å½•çº§åˆ†é…
            if not assigned and include_fallback:
                print(f" ğŸ”„ å¯ç”¨å¤‡é€‰åˆ†é…æ–¹æ¡ˆ...")
                fallback_assignee, fallback_stats, fallback_source = self.find_fallback_assignee(group['files'], active_contributors)

                if fallback_assignee and fallback_assignee not in all_excluded:
                    current_count = assignment_count.get(fallback_assignee, 0)
                    if current_count < max_tasks_per_person:
                        group["assignee"] = fallback_assignee
                        assignment_count[fallback_assignee] = current_count + 1
                        group["fallback_reason"] = f"é€šè¿‡{fallback_source}ç›®å½•åˆ†æåˆ†é…"
                        assignment_reason = f"å¤‡é€‰ç›®å½•åˆ†é… (æ¥æº:{fallback_source}, ä¸€å¹´å†…:{fallback_stats['recent_commits']}, å†å²:{fallback_stats['total_commits']}, å¾—åˆ†:{fallback_stats['score']})"
                        print(f" âœ… å¤‡é€‰åˆ†é…ç»™: {fallback_assignee} (æ¥æº: {fallback_source})")
                        print(f" ç›®å½•è´¡çŒ® - ä¸€å¹´å†…: {fallback_stats['recent_commits']}, å†å²: {fallback_stats['total_commits']}, å¾—åˆ†: {fallback_stats['score']}")
                        assigned = True

            if not assigned:
                unassigned_groups.append(group['name'])
                if main_contributor:
                    if main_contributor in all_excluded:
                        if main_contributor in inactive_contributors:
                            assignment_reason = f"ä¸»è¦è´¡çŒ®è€…{main_contributor}è¿‘3ä¸ªæœˆæ— æ´»è·ƒæäº¤ï¼Œå·²è‡ªåŠ¨æ’é™¤"
                            print(f" âš ï¸ ä¸»è¦è´¡çŒ®è€… {main_contributor} è¿‘3ä¸ªæœˆæ— æ´»è·ƒæäº¤ï¼Œå·²è‡ªåŠ¨æ’é™¤")
                            group["notes"] = f"å»ºè®®: {main_contributor} (è¿‘æœŸæ´»è·ƒåº¦ä¸è¶³ï¼Œå·²è‡ªåŠ¨æ’é™¤)"
                        else:
                            assignment_reason = f"ä¸»è¦è´¡çŒ®è€…{main_contributor}åœ¨æ‰‹åŠ¨æ’é™¤åˆ—è¡¨ä¸­"
                            print(f" âš ï¸ ä¸»è¦è´¡çŒ®è€… {main_contributor} åœ¨æ‰‹åŠ¨æ’é™¤åˆ—è¡¨ä¸­")
                            main_stats = all_contributors[main_contributor]
                            group["notes"] = f"å»ºè®®: {main_contributor} (è¿‘æœŸ:{main_stats['recent_commits']},å†å²:{main_stats['total_commits']},å¾—åˆ†:{main_stats['score']}) å·²æ‰‹åŠ¨æ’é™¤"
                    else:
                        assignment_reason = f"ä¸»è¦è´¡çŒ®è€…{main_contributor}å·²è¾¾æœ€å¤§ä»»åŠ¡æ•°{max_tasks_per_person}"
                        main_stats = all_contributors[main_contributor]
                        group["notes"] = f"å»ºè®®: {main_contributor} (è¿‘æœŸ:{main_stats['recent_commits']},å†å²:{main_stats['total_commits']},å¾—åˆ†:{main_stats['score']}) ä½†å·²è¾¾æœ€å¤§ä»»åŠ¡æ•°"
                        print(f" âš ï¸ ä¸»è¦è´¡çŒ®è€… {main_contributor} å·²è¾¾æœ€å¤§ä»»åŠ¡æ•°")
                else:
                    assignment_reason = "æ— æ³•ç¡®å®šä¸»è¦è´¡çŒ®è€…"
                    print(f" âš ï¸ æ— æ³•ç¡®å®šä¸»è¦è´¡çŒ®è€…ï¼Œè¯·æ‰‹åŠ¨åˆ†é…")
                    group["notes"] = "æ— æ³•ç¡®å®šä¸»è¦è´¡çŒ®è€…"

            # ä¿å­˜åˆ†é…åŸå› å’Œè´¡çŒ®è€…ä¿¡æ¯
            group["assignment_reason"] = assignment_reason
            group["contributors"] = all_contributors

        # ä¿å­˜æ›´æ–°åçš„è®¡åˆ’
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan, f, indent=2, ensure_ascii=False)

        # æ˜¾ç¤ºåˆ†é…æ€»ç»“
        print(f"\nğŸ“Š è‡ªåŠ¨åˆ†é…æ€»ç»“:")
        print(f"ğŸ¯ æ´»è·ƒè´¡çŒ®è€…: {len(active_contributors)} ä½")
        print(f"ğŸš« è‡ªåŠ¨æ’é™¤: {len(inactive_contributors)} ä½ï¼ˆè¿‘3ä¸ªæœˆæ— æäº¤ï¼‰")
        print(f"ğŸ”§ æ‰‹åŠ¨æ’é™¤: {len(exclude_authors)} ä½")
        print(f"\nğŸ‘¥ ä»»åŠ¡åˆ†é…:")
        for person, count in sorted(assignment_count.items(), key=lambda x: x[1], reverse=True):
            print(f" {person}: {count} ä¸ªä»»åŠ¡")

        if unassigned_groups:
            print(f"\nâš ï¸ æœªåˆ†é…çš„ç»„ ({len(unassigned_groups)}ä¸ª): {', '.join(unassigned_groups[:3])}" + ("..." if len(unassigned_groups) > 3 else ""))

        print("âœ… æ™ºèƒ½è‡ªåŠ¨åˆ†é…å®Œæˆ")
        return plan

    def assign_tasks(self, assignments=None):
        """åˆ†é…åˆå¹¶ä»»åŠ¡ï¼ˆæ‰‹åŠ¨æˆ–è‡ªåŠ¨ï¼‰"""
        if assignments is None:
            return self.auto_assign_tasks()

        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return None

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        for group_name, assignee in assignments.items():
            for group in plan["groups"]:
                if group["name"] == group_name:
                    group["assignee"] = assignee
                    group["assignment_reason"] = "æ‰‹åŠ¨åˆ†é…"
                    break

        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan, f, indent=2, ensure_ascii=False)

        print("âœ… ä»»åŠ¡åˆ†é…å®Œæˆ")
        return plan

    def view_group_details(self, group_name=None):
        """æŸ¥çœ‹åˆ†ç»„è¯¦ç»†ä¿¡æ¯ - æ˜¾ç¤ºå…·ä½“æ–‡ä»¶å’Œåˆ†é…åŸå› """
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return []

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        if group_name:
            # æŸ¥çœ‹æŒ‡å®šç»„çš„è¯¦ç»†ä¿¡æ¯
            target_group = None
            for group in plan["groups"]:
                if group["name"] == group_name:
                    target_group = group
                    break

            if not target_group:
                print(f"âŒ æœªæ‰¾åˆ°ç»„: {group_name}")
                return []

            self._display_group_detail(target_group)
            return [target_group]
        else:
            # äº¤äº’å¼é€‰æ‹©æŸ¥çœ‹
            print("ğŸ“‹ å¯ç”¨åˆ†ç»„åˆ—è¡¨:")

            # ä¼˜åŒ–è¡¨æ ¼æ˜¾ç¤º - ä½¿ç”¨å›ºå®šåˆ—å®½
            headers = ["åºå·", "ç»„å", "ç±»å‹", "æ–‡ä»¶æ•°", "è´Ÿè´£äºº", "çŠ¶æ€"]
            widths = [6, 30, 18, 8, 20, 8]
            aligns = ['center', 'left', 'left', 'center', 'left', 'center']

            self._print_table_header(headers, widths, aligns)

            for i, group in enumerate(plan["groups"], 1):
                assignee = group.get("assignee", "æœªåˆ†é…")
                status = "âœ…" if group.get("status") == "completed" else "ğŸ”„" if assignee != "æœªåˆ†é…" else "â³"
                group_type = group.get("group_type", "unknown")
                file_count = group.get("file_count", len(group["files"]))

                values = [str(i), group['name'], group_type, str(file_count), assignee, status]
                self._print_table_row(values, widths, aligns)

            self._print_table_separator(widths)

            try:
                choice = input("è¯·è¾“å…¥è¦æŸ¥çœ‹çš„ç»„åºå· (å›è½¦è¿”å›): ").strip()
                if not choice:
                    return []

                index = int(choice) - 1
                if 0 <= index < len(plan["groups"]):
                    selected_group = plan["groups"][index]
                    self._display_group_detail(selected_group)
                    return [selected_group]
                else:
                    print("âŒ æ— æ•ˆçš„åºå·")
                    return []
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                return []

    def _display_group_detail(self, group):
        """æ˜¾ç¤ºå•ä¸ªç»„çš„è¯¦ç»†ä¿¡æ¯"""
        print("\n" + "="*100)
        print(f"ğŸ“ ç»„è¯¦ç»†ä¿¡æ¯: {group['name']}")
        print("="*100)

        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"   ç»„å: {group['name']}")
        print(f"   ç±»å‹: {group.get('group_type', 'unknown')} ({self._get_group_type_description(group.get('group_type', 'unknown'))})")
        print(f"   æ–‡ä»¶æ•°: {group.get('file_count', len(group['files']))} ä¸ª")
        print(f"   è´Ÿè´£äºº: {group.get('assignee', 'æœªåˆ†é…')}")
        print(f"   çŠ¶æ€: {'âœ… å·²å®Œæˆ' if group.get('status') == 'completed' else 'ğŸ”„ è¿›è¡Œä¸­' if group.get('assignee') else 'â³ å¾…åˆ†é…'}")

        # åˆ†é…åŸå› 
        assignment_reason = group.get('assignment_reason', 'æœªæŒ‡å®š')
        if assignment_reason:
            print(f"   åˆ†é…åŸå› : {assignment_reason}")

        # å¤‡é€‰åˆ†é…ä¿¡æ¯
        fallback_reason = group.get('fallback_reason', '')
        if fallback_reason:
            print(f"   å¤‡é€‰åŸå› : {fallback_reason}")

        # æ–‡ä»¶åˆ—è¡¨
        print(f"\nğŸ“„ åŒ…å«æ–‡ä»¶åˆ—è¡¨:")
        files = group.get('files', [])
        for i, file_path in enumerate(files, 1):
            print(f"   {i:2d}. {file_path}")

        # è´¡çŒ®è€…åˆ†æ - ä¼˜åŒ–è¡¨æ ¼æ˜¾ç¤º
        contributors = group.get('contributors', {})
        if contributors:
            print(f"\nğŸ‘¥ è´¡çŒ®è€…åˆ†æ (åŸºäºä¸€å¹´å†…æ´»è·ƒåº¦):")

            headers = ["æ’å", "è´¡çŒ®è€…", "ä¸€å¹´å†…", "å†å²æ€»è®¡", "ç»¼åˆå¾—åˆ†", "å‚ä¸æ–‡ä»¶"]
            widths = [6, 25, 10, 12, 12, 12]
            aligns = ['center', 'left', 'center', 'center', 'center', 'center']

            self._print_table_header(headers, widths, aligns)

            sorted_contributors = sorted(contributors.items(), key=lambda x: x[1]['score'] if isinstance(x[1], dict) else x[1], reverse=True)
            for i, (author, stats) in enumerate(sorted_contributors[:10], 1):
                if isinstance(stats, dict):
                    recent = stats.get('recent_commits', 0)
                    total = stats.get('total_commits', 0)
                    score = stats.get('score', 0)
                    file_count = stats.get('file_count', 0)
                    values = [str(i), author, str(recent), str(total), str(score), str(file_count)]
                else:
                    values = [str(i), author, 'N/A', str(stats), str(stats), 'N/A']

                self._print_table_row(values, widths, aligns)

            if len(sorted_contributors) > 10:
                print(f"   ... è¿˜æœ‰ {len(sorted_contributors) - 10} ä½è´¡çŒ®è€…")

        # å¤‡æ³¨ä¿¡æ¯
        notes = group.get('notes', '')
        if notes:
            print(f"\nğŸ“ å¤‡æ³¨: {notes}")

        print("="*100)

    def _get_group_type_description(self, group_type):
        """è·å–åˆ†ç»„ç±»å‹çš„æè¿°"""
        descriptions = {
            'simple_group': 'ç®€å•åˆ†ç»„ - æ–‡ä»¶æ•°é‡è¾ƒå°‘ï¼Œç›´æ¥åˆ†ç»„',
            'direct_files': 'ç›´æ¥æ–‡ä»¶ - ç›®å½•ä¸‹çš„ç›´æ¥æ–‡ä»¶',
            'subdir_group': 'å­ç›®å½•åˆ†ç»„ - æŒ‰å­ç›®å½•åˆ’åˆ†',
            'alpha_group': 'å­—æ¯åˆ†ç»„ - æ ¹ç›®å½•æ–‡ä»¶æŒ‰é¦–å­—æ¯åˆ†ç»„',
            'batch_group': 'æ‰¹é‡åˆ†ç»„ - å¤§é‡æ–‡ä»¶åˆ†æ‰¹å¤„ç†',
            'fallback_batch': 'å›é€€æ‰¹é‡ - åˆ†ç»„å¤±è´¥åçš„ç®€å•æ‰¹é‡å¤„ç†'
        }
        return descriptions.get(group_type, 'æœªçŸ¥ç±»å‹')

    def show_assignment_reasons(self):
        """æ˜¾ç¤ºæ‰€æœ‰ç»„çš„åˆ†é…åŸå› åˆ†æ"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        print("\nğŸ“Š ä»»åŠ¡åˆ†é…åŸå› åˆ†ææŠ¥å‘Š")
        print("="*120)

        # ç»Ÿè®¡åˆ†é…åŸå› ç±»å‹
        reason_stats = defaultdict(list)
        for group in plan["groups"]:
            assignment_reason = group.get('assignment_reason', 'æœªæŒ‡å®š')
            reason_type = self._categorize_assignment_reason(assignment_reason)
            reason_stats[reason_type].append(group)

        print("ğŸ“ˆ åˆ†é…åŸå› ç»Ÿè®¡:")
        for reason_type, groups in reason_stats.items():
            print(f"   {reason_type}: {len(groups)} ä¸ªç»„")

        print()

        # ä¼˜åŒ–è¡¨æ ¼æ˜¾ç¤º
        headers = ["ç»„å", "è´Ÿè´£äºº", "æ–‡ä»¶æ•°", "åˆ†é…ç±»å‹", "è¯¦ç»†åŸå› "]
        widths = [30, 20, 8, 18, 50]
        aligns = ['left', 'left', 'center', 'left', 'left']

        self._print_table_header(headers, widths, aligns)

        for group in plan["groups"]:
            assignee = group.get('assignee', 'æœªåˆ†é…')
            file_count = group.get('file_count', len(group['files']))
            assignment_reason = group.get('assignment_reason', 'æœªæŒ‡å®š')
            reason_type = self._categorize_assignment_reason(assignment_reason)

            # æˆªæ–­è¿‡é•¿çš„åŸå› è¯´æ˜
            short_reason = assignment_reason[:45] + "..." if len(assignment_reason) > 45 else assignment_reason

            values = [group['name'], assignee, str(file_count), reason_type, short_reason]
            self._print_table_row(values, widths, aligns)

        self._print_table_separator(widths)

        # åˆ†ç±»è¯¦ç»†å±•ç¤º
        print(f"\nğŸ“‹ åˆ†ç±»è¯¦ç»†åˆ†æ:")
        for reason_type, groups in reason_stats.items():
            if not groups:
                continue

            print(f"\nğŸ” {reason_type} ({len(groups)} ä¸ªç»„):")
            for group in groups[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                assignee = group.get('assignee', 'æœªåˆ†é…')
                assignment_reason = group.get('assignment_reason', 'æœªæŒ‡å®š')
                print(f"   - {group['name']} â†’ {assignee}")
                print(f"     åŸå› : {assignment_reason}")

            if len(groups) > 5:
                print(f"   ... è¿˜æœ‰ {len(groups) - 5} ä¸ªç»„")

    def _categorize_assignment_reason(self, reason):
        """å°†åˆ†é…åŸå› åˆ†ç±»"""
        if not reason or reason == 'æœªæŒ‡å®š':
            return 'æœªæŒ‡å®š'
        elif 'åŸºäºæ–‡ä»¶è´¡çŒ®åº¦ç›´æ¥åˆ†é…' in reason:
            return 'ç›´æ¥åˆ†é…'
        elif 'è´Ÿè½½å‡è¡¡åˆ†é…' in reason:
            return 'è´Ÿè½½å‡è¡¡'
        elif 'å¤‡é€‰ç›®å½•åˆ†é…' in reason:
            return 'å¤‡é€‰åˆ†é…'
        elif 'æ‰‹åŠ¨åˆ†é…' in reason:
            return 'æ‰‹åŠ¨åˆ†é…'
        elif 'æ— æ³•ç¡®å®šä¸»è¦è´¡çŒ®è€…' in reason:
            return 'æ— è´¡çŒ®è€…'
        elif 'å·²è‡ªåŠ¨æ’é™¤' in reason:
            return 'è‡ªåŠ¨æ’é™¤'
        elif 'å·²è¾¾æœ€å¤§ä»»åŠ¡æ•°' in reason:
            return 'ä»»åŠ¡æ»¡è½½'
        else:
            return 'å…¶ä»–'

    def search_assignee_tasks(self, assignee_name):
        """æ ¹æ®è´Ÿè´£äººæœç´¢å…¶è´Ÿè´£çš„æ‰€æœ‰æ¨¡å—"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return []

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        assignee_groups = []
        total_files = 0

        for group in plan["groups"]:
            if group.get("assignee", "").lower() == assignee_name.lower():
                assignee_groups.append(group)
                total_files += group.get("file_count", len(group["files"]))

        if not assignee_groups:
            print(f"ğŸ“‹ è´Ÿè´£äºº '{assignee_name}' æš‚æ— åˆ†é…çš„ä»»åŠ¡")
            return []

        print(f"ğŸ‘¤ è´Ÿè´£äºº: {assignee_name}")
        print(f"ğŸ“Š æ€»è§ˆ: {len(assignee_groups)} ä¸ªç»„, {total_files} ä¸ªæ–‡ä»¶")

        # ä¼˜åŒ–è¡¨æ ¼æ˜¾ç¤º
        headers = ["ç»„å", "æ–‡ä»¶æ•°", "çŠ¶æ€", "ç±»å‹", "åˆ†é…åŸå› "]
        widths = [30, 8, 8, 18, 40]
        aligns = ['left', 'center', 'center', 'left', 'left']

        self._print_table_header(headers, widths, aligns)

        completed = 0
        pending = 0

        for group in assignee_groups:
            status = group.get("status", "pending")
            status_icon = "âœ…" if status == "completed" else "ğŸ”„"
            file_count = group.get("file_count", len(group["files"]))
            group_type = group.get("group_type", "unknown")
            assignment_reason = group.get("assignment_reason", "æœªæŒ‡å®š")

            if status == "completed":
                completed += 1
            else:
                pending += 1

            # æˆªæ–­é•¿çš„åˆ†é…åŸå› 
            short_reason = assignment_reason[:35] + "..." if len(assignment_reason) > 35 else assignment_reason

            values = [group['name'], str(file_count), status_icon, group_type, short_reason]
            self._print_table_row(values, widths, aligns)

        self._print_table_separator(widths)
        print(f"ğŸ“ˆ è¿›åº¦: {completed}/{len(assignee_groups)} ç»„å·²å®Œæˆ, {pending} ç»„å¾…å¤„ç†")

        # æ˜¾ç¤ºè¯¦ç»†æ–‡ä»¶åˆ—è¡¨
        if len(assignee_groups) <= 3:  # åªæœ‰å°‘é‡ç»„æ—¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            print(f"\nğŸ“„ è¯¦ç»†æ–‡ä»¶åˆ—è¡¨:")
            for i, group in enumerate(assignee_groups, 1):
                print(f"\n{i}. ç»„: {group['name']} ({group.get('file_count', len(group['files']))} æ–‡ä»¶)")
                assignment_reason = group.get("assignment_reason", "æœªæŒ‡å®š")
                print(f"   åˆ†é…åŸå› : {assignment_reason}")
                for file in group['files'][:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªæ–‡ä»¶
                    print(f"   - {file}")
                if len(group['files']) > 5:
                    print(f"   ... è¿˜æœ‰ {len(group['files']) - 5} ä¸ªæ–‡ä»¶")

        return assignee_groups

    def create_merge_branch(self, group_name, assignee):
        """ä¸ºæŒ‡å®šä»»åŠ¡åˆ›å»ºåˆå¹¶åˆ†æ”¯"""
        branch_name = f"feat/merge-{group_name.replace('/', '-')}-{assignee.replace(' ', '-')}"

        # åˆ›å»ºå·¥ä½œåˆ†æ”¯
        self.run_git_command(f"git checkout {self.integration_branch}")
        result = self.run_git_command(f"git checkout -b {branch_name}")

        if result is not None:
            print(f"âœ… å·²åˆ›å»ºåˆå¹¶åˆ†æ”¯: {branch_name}")
        else:
            print(f"âš ï¸ åˆ†æ”¯ {branch_name} å¯èƒ½å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆ‡æ¢")
            self.run_git_command(f"git checkout {branch_name}")

        return branch_name

    def check_file_existence(self, files, branch):
        """æ£€æŸ¥æ–‡ä»¶åœ¨æŒ‡å®šåˆ†æ”¯ä¸­æ˜¯å¦å­˜åœ¨"""
        existing_files = []
        missing_files = []

        for file in files:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æŒ‡å®šåˆ†æ”¯ä¸­å­˜åœ¨
            result = self.run_git_command(f"git cat-file -e {branch}:{file} 2>/dev/null")
            if result is not None:
                existing_files.append(file)
            else:
                missing_files.append(file)

        return existing_files, missing_files

    def generate_smart_merge_script(self, group_name, assignee, files, branch_name):
        """ç”Ÿæˆæ™ºèƒ½åˆå¹¶è„šæœ¬ï¼Œå¤„ç†æ–°æ–‡ä»¶å’Œå·²å­˜åœ¨æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        existing_files, missing_files = self.check_file_existence(files, self.target_branch)

        print(f"ğŸ“Š æ–‡ä»¶åˆ†æ:")
        print(f"  - å·²å­˜åœ¨æ–‡ä»¶: {len(existing_files)} ä¸ª")
        print(f"  - æ–°å¢æ–‡ä»¶: {len(missing_files)} ä¸ª")

        # ç”Ÿæˆå¤„ç†è„šæœ¬
        script_content = f"""#!/bin/bash
# æ™ºèƒ½åˆå¹¶è„šæœ¬ - {group_name} (è´Ÿè´£äºº: {assignee})
# æ–‡ä»¶æ•°: {len(files)} (å·²å­˜åœ¨: {len(existing_files)}, æ–°å¢: {len(missing_files)})
# åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

set -e # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸš€ å¼€å§‹æ™ºèƒ½åˆå¹¶ç»„: {group_name}"
echo "ğŸ‘¤ è´Ÿè´£äºº: {assignee}"
echo "ğŸŒ¿ å·¥ä½œåˆ†æ”¯: {branch_name}"
echo "ğŸ“ æ€»æ–‡ä»¶æ•°: {len(files)}"
echo "ğŸ“Š å·²å­˜åœ¨æ–‡ä»¶: {len(existing_files)}"
echo "ğŸ“Š æ–°å¢æ–‡ä»¶: {len(missing_files)}"
echo ""

# åˆ‡æ¢åˆ°å·¥ä½œåˆ†æ”¯
echo "ğŸ“‹ åˆ‡æ¢åˆ°å·¥ä½œåˆ†æ”¯..."
git checkout {branch_name}

echo "ğŸ“„ æ–‡ä»¶è¯¦æƒ…:"
"""

        if existing_files:
            script_content += f"""
echo "âœ… å·²å­˜åœ¨æ–‡ä»¶ ({len(existing_files)}ä¸ª):"
{chr(10).join([f'echo "  - {file}"' for file in existing_files])}
"""

        if missing_files:
            script_content += f"""
echo "ğŸ†• æ–°å¢æ–‡ä»¶ ({len(missing_files)}ä¸ª):"
{chr(10).join([f'echo "  - {file}"' for file in missing_files])}
"""

        script_content += f"""
echo ""

# æ™ºèƒ½åˆå¹¶ç­–ç•¥
merge_success=true

echo "ğŸ”„ å¼€å§‹æ™ºèƒ½é€‰æ‹©æ€§åˆå¹¶..."
"""

        # å¤„ç†å·²å­˜åœ¨æ–‡ä»¶
        if existing_files:
            script_content += f"""
echo "ğŸ“ å¤„ç†å·²å­˜åœ¨æ–‡ä»¶..."
if git checkout {self.source_branch} -- {' '.join([f'"{f}"' for f in existing_files])}; then
    echo "âœ… å·²å­˜åœ¨æ–‡ä»¶åˆå¹¶æˆåŠŸ"
else
    echo "âš ï¸ å·²å­˜åœ¨æ–‡ä»¶åˆå¹¶æ—¶å‡ºç°é—®é¢˜"
    merge_success=false
fi
"""

        # å¤„ç†æ–°å¢æ–‡ä»¶
        if missing_files:
            script_content += f"""
echo "ğŸ†• å¤„ç†æ–°å¢æ–‡ä»¶..."
"""
            for file in missing_files:
                script_content += f"""
echo "  å¤„ç†æ–°æ–‡ä»¶: {file}"
# åˆ›å»ºç›®å½•ç»“æ„
mkdir -p "$(dirname "{file}")"
# ä»æºåˆ†æ”¯å¤åˆ¶æ–‡ä»¶å†…å®¹
if git show {self.source_branch}:{file} > "{file}" 2>/dev/null; then
    git add "{file}"
    echo "    âœ… æ–°æ–‡ä»¶ {file} æ·»åŠ æˆåŠŸ"
else
    echo "    âŒ æ— æ³•ä»æºåˆ†æ”¯è·å–æ–‡ä»¶: {file}"
    merge_success=false
fi
"""

        script_content += f"""
echo ""

if [ "$merge_success" = true ]; then
    echo "âœ… æ™ºèƒ½åˆå¹¶å®Œæˆ!"
    echo ""
    echo "ğŸ“Š åˆå¹¶çŠ¶æ€:"
    git status --short
    echo ""
    echo "ğŸ” æ–‡ä»¶å·®å¼‚æ¦‚è§ˆ:"
    git diff --cached --stat 2>/dev/null || echo "(æ–°æ–‡ä»¶æ— å·®å¼‚æ˜¾ç¤º)"
    echo ""
    echo "â­ï¸ ä¸‹ä¸€æ­¥æ“ä½œï¼š"
    echo " 1. æ£€æŸ¥åˆå¹¶ç»“æœ: git diff --cached"
    echo " 2. æ£€æŸ¥æ–°æ–‡ä»¶å†…å®¹: git diff --no-index /dev/null <æ–‡ä»¶å>"
    echo " 3. æäº¤æ›´æ”¹: git commit -m 'Merge group: {group_name} ({len(files)} files)'"
    echo " 4. æ¨é€åˆ†æ”¯: git push origin {branch_name}"
    echo ""
    echo "ğŸ”„ å¦‚éœ€å›æ»š: git reset --hard HEAD"
else
    echo "âŒ æ™ºèƒ½åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜"
    echo "ğŸ”§ å¯èƒ½çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼š"
    echo " 1. æ–‡ä»¶åœ¨æºåˆ†æ”¯ä¸­ä¸å­˜åœ¨ - è¯·æ£€æŸ¥åˆ†æ”¯å’Œæ–‡ä»¶è·¯å¾„"
    echo " 2. æƒé™é—®é¢˜ - è¯·æ£€æŸ¥æ–‡ä»¶å’Œç›®å½•æƒé™"
    echo " 3. è·¯å¾„é—®é¢˜ - è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®"
    echo ""
    echo "ğŸ“Š å½“å‰çŠ¶æ€:"
    git status
    echo ""
    echo "ğŸ› ï¸ æ‰‹åŠ¨å¤„ç†æ­¥éª¤ï¼š"
    echo " 1. æ£€æŸ¥å…·ä½“é”™è¯¯: æŸ¥çœ‹ä¸Šæ–¹é”™è¯¯ä¿¡æ¯"
    echo " 2. æ‰‹åŠ¨å¤åˆ¶é—®é¢˜æ–‡ä»¶: cp source/path target/path"
    echo " 3. æ·»åŠ æ–‡ä»¶: git add <files>"
    echo " 4. æäº¤: git commit -m 'Manual merge: {group_name}'"
    exit 1
fi
"""

        return script_content

    def merge_group(self, group_name):
        """åˆå¹¶æŒ‡å®šç»„çš„æ–‡ä»¶ - æ™ºèƒ½å¤„ç†æ–°æ–‡ä»¶å’Œå·²å­˜åœ¨æ–‡ä»¶"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return False

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        # æ‰¾åˆ°å¯¹åº”ç»„
        group_info = None
        for group in plan["groups"]:
            if group["name"] == group_name:
                group_info = group
                break

        if not group_info:
            print(f"âŒ æœªæ‰¾åˆ°ç»„: {group_name}")
            return False

        assignee = group_info["assignee"]
        if not assignee:
            print(f"âŒ ç»„ {group_name} å°šæœªåˆ†é…è´Ÿè´£äºº")
            return False

        # åˆ›å»ºåˆå¹¶åˆ†æ”¯
        branch_name = self.create_merge_branch(group_name, assignee)

        # ç”Ÿæˆæ™ºèƒ½åˆå¹¶è„šæœ¬
        script_content = self.generate_smart_merge_script(
            group_name, assignee, group_info["files"], branch_name
        )

        script_file = self.work_dir / f"merge_{group_name.replace('/', '_')}.sh"
        with open(script_file, 'w') as f:
            f.write(script_content)

        os.chmod(script_file, 0o755)

        print(f"âœ… å·²ç”Ÿæˆæ™ºèƒ½åˆå¹¶è„šæœ¬: {script_file}")
        print(f"ğŸ¯ è¯·æ‰§è¡Œ: ./{script_file}")

        return True

    def finalize_merge(self):
        """å®Œæˆæœ€ç»ˆåˆå¹¶"""
        print("ğŸ¯ å¼€å§‹æœ€ç»ˆåˆå¹¶...")

        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨")
            return False

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        # åˆ‡æ¢åˆ°é›†æˆåˆ†æ”¯
        self.run_git_command(f"git checkout {self.integration_branch}")

        # æ£€æŸ¥å“ªäº›åˆ†æ”¯å·²å®Œæˆ
        completed_branches = []
        for group in plan["groups"]:
            if group["status"] == "completed" and group.get("assignee"):
                branch_name = f"feat/merge-{group['name'].replace('/', '-')}-{group['assignee'].replace(' ', '-')}"
                # æ£€æŸ¥åˆ†æ”¯æ˜¯å¦å­˜åœ¨
                if self.run_git_command(f"git show-ref --verify --quiet refs/heads/{branch_name}") is not None:
                    completed_branches.append((branch_name, group))

        if not completed_branches:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å·²å®Œæˆçš„åˆå¹¶åˆ†æ”¯")
            return False

        print(f"ğŸ” å‘ç° {len(completed_branches)} ä¸ªå·²å®Œæˆçš„åˆ†æ”¯:")
        total_files = 0
        for branch_name, group in completed_branches:
            file_count = group.get('file_count', len(group['files']))
            total_files += file_count
            print(f" - {branch_name} ({file_count} æ–‡ä»¶)")

        print(f"ğŸ“Š æ€»è®¡å°†åˆå¹¶ {total_files} ä¸ªæ–‡ä»¶")

        # åˆå¹¶æ‰€æœ‰å®Œæˆçš„åˆ†æ”¯
        for branch_name, group in completed_branches:
            print(f"ğŸ”„ æ­£åœ¨åˆå¹¶åˆ†æ”¯: {branch_name}")
            result = self.run_git_command(f"git merge --no-ff -m 'Merge branch {branch_name}: {group['name']}' {branch_name}")
            if result is not None:
                print(f" âœ… æˆåŠŸåˆå¹¶ {branch_name}")
            else:
                print(f" âŒ åˆå¹¶ {branch_name} æ—¶å‡ºç°é—®é¢˜")
                return False

        print("ğŸ‰ æœ€ç»ˆåˆå¹¶å®Œæˆ!")
        print(f"ğŸ“‹ é›†æˆåˆ†æ”¯ {self.integration_branch} å·²åŒ…å«æ‰€æœ‰æ›´æ”¹")
        print(f"ğŸš€ å»ºè®®æ“ä½œ:")
        print(f" 1. éªŒè¯åˆå¹¶ç»“æœ: git log --oneline -10")
        print(f" 2. æ¨é€åˆ°è¿œç¨‹: git push origin {self.integration_branch}")
        print(f" 3. åˆ›å»ºPR/MRåˆå¹¶åˆ° {self.target_branch}")
        return True

    def merge_assignee_tasks(self, assignee_name):
        """åˆå¹¶æŒ‡å®šè´Ÿè´£äººçš„æ‰€æœ‰ä»»åŠ¡ - æ™ºèƒ½å¤„ç†æ–°æ–‡ä»¶å’Œå·²å­˜åœ¨æ–‡ä»¶"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return False

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        # æ‰¾åˆ°è´Ÿè´£äººçš„æ‰€æœ‰ä»»åŠ¡
        assignee_groups = []
        for group in plan["groups"]:
            if group.get("assignee", "").lower() == assignee_name.lower():
                assignee_groups.append(group)

        if not assignee_groups:
            print(f"âŒ è´Ÿè´£äºº '{assignee_name}' æ²¡æœ‰åˆ†é…çš„ä»»åŠ¡")
            return False

        print(f"ğŸ¯ å¼€å§‹æ‰¹é‡åˆå¹¶è´Ÿè´£äºº '{assignee_name}' çš„æ‰€æœ‰ä»»åŠ¡...")
        print(f"ğŸ“‹ å…± {len(assignee_groups)} ä¸ªç»„ï¼Œæ€»è®¡ {sum(g.get('file_count', len(g['files'])) for g in assignee_groups)} ä¸ªæ–‡ä»¶")

        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶
        all_files = []
        for group in assignee_groups:
            all_files.extend(group["files"])

        if not all_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦åˆå¹¶çš„æ–‡ä»¶")
            return False

        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        existing_files, missing_files = self.check_file_existence(all_files, self.target_branch)

        print(f"ğŸ“Š æ‰¹é‡åˆå¹¶æ–‡ä»¶åˆ†æ:")
        print(f"  - å·²å­˜åœ¨æ–‡ä»¶: {len(existing_files)} ä¸ª")
        print(f"  - æ–°å¢æ–‡ä»¶: {len(missing_files)} ä¸ª")

        # åˆ›å»ºç»Ÿä¸€çš„åˆå¹¶åˆ†æ”¯
        batch_branch_name = f"feat/merge-batch-{assignee_name.replace(' ', '-')}-{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        print(f"\nğŸŒ¿ åˆ›å»ºæ‰¹é‡åˆå¹¶åˆ†æ”¯: {batch_branch_name}")
        self.run_git_command(f"git checkout {self.integration_branch}")
        result = self.run_git_command(f"git checkout -b {batch_branch_name}")

        if result is None:
            print(f"âš ï¸ åˆ†æ”¯åˆ›å»ºå¯èƒ½å¤±è´¥ï¼Œå°è¯•åˆ‡æ¢åˆ°ç°æœ‰åˆ†æ”¯")
            self.run_git_command(f"git checkout {batch_branch_name}")

        # ç”Ÿæˆæ™ºèƒ½æ‰¹é‡åˆå¹¶è„šæœ¬
        script_content = f"""#!/bin/bash
# æ‰¹é‡æ™ºèƒ½åˆå¹¶è„šæœ¬ - è´Ÿè´£äºº: {assignee_name}
# ç»„æ•°: {len(assignee_groups)} (æ–‡ä»¶æ€»æ•°: {len(all_files)}, å·²å­˜åœ¨: {len(existing_files)}, æ–°å¢: {len(missing_files)})
# åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

set -e # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸš€ å¼€å§‹æ‰¹é‡æ™ºèƒ½åˆå¹¶è´Ÿè´£äºº '{assignee_name}' çš„æ‰€æœ‰ä»»åŠ¡"
echo "ğŸŒ¿ å·¥ä½œåˆ†æ”¯: {batch_branch_name}"
echo "ğŸ“ æ€»æ–‡ä»¶æ•°: {len(all_files)}"
echo "ğŸ“Š å·²å­˜åœ¨æ–‡ä»¶: {len(existing_files)}"
echo "ğŸ“Š æ–°å¢æ–‡ä»¶: {len(missing_files)}"
echo "ğŸ“‹ åŒ…å«ç»„: {', '.join([g['name'] for g in assignee_groups])}"
echo ""

# åˆ‡æ¢åˆ°å·¥ä½œåˆ†æ”¯
echo "ğŸ“‹ åˆ‡æ¢åˆ°å·¥ä½œåˆ†æ”¯..."
git checkout {batch_branch_name}

echo "ğŸ“„ ç»„åˆ«è¯¦æƒ…:"
{chr(10).join([f'echo "  ç»„ {g["name"]}: {g.get("file_count", len(g["files"]))} ä¸ªæ–‡ä»¶"' for g in assignee_groups])}
echo ""

# æ™ºèƒ½åˆå¹¶ç­–ç•¥
merge_success=true

echo "ğŸ”„ å¼€å§‹æ‰¹é‡æ™ºèƒ½é€‰æ‹©æ€§åˆå¹¶..."
"""

        # å¤„ç†å·²å­˜åœ¨æ–‡ä»¶
        if existing_files:
            script_content += f"""
echo "ğŸ“ å¤„ç†å·²å­˜åœ¨æ–‡ä»¶ ({len(existing_files)}ä¸ª)..."
if git checkout {self.source_branch} -- {' '.join([f'"{f}"' for f in existing_files])}; then
    echo "âœ… å·²å­˜åœ¨æ–‡ä»¶æ‰¹é‡åˆå¹¶æˆåŠŸ"
else
    echo "âš ï¸ éƒ¨åˆ†å·²å­˜åœ¨æ–‡ä»¶åˆå¹¶æ—¶å‡ºç°é—®é¢˜"
    merge_success=false
fi
"""

        # å¤„ç†æ–°å¢æ–‡ä»¶
        if missing_files:
            script_content += f"""
echo "ğŸ†• å¤„ç†æ–°å¢æ–‡ä»¶ ({len(missing_files)}ä¸ª)..."
"""
            for file in missing_files:
                script_content += f"""
echo "  å¤„ç†æ–°æ–‡ä»¶: {file}"
# åˆ›å»ºç›®å½•ç»“æ„
mkdir -p "$(dirname "{file}")"
# ä»æºåˆ†æ”¯å¤åˆ¶æ–‡ä»¶å†…å®¹
if git show {self.source_branch}:{file} > "{file}" 2>/dev/null; then
    git add "{file}"
    echo "    âœ… æ–°æ–‡ä»¶ {file} æ·»åŠ æˆåŠŸ"
else
    echo "    âŒ æ— æ³•ä»æºåˆ†æ”¯è·å–æ–‡ä»¶: {file}"
    merge_success=false
fi
"""

        script_content += f"""
echo ""

if [ "$merge_success" = true ]; then
    echo "âœ… æ‰¹é‡æ™ºèƒ½åˆå¹¶å®Œæˆ!"
    echo ""
    echo "ğŸ“Š åˆå¹¶çŠ¶æ€:"
    git status --short
    echo ""
    echo "ğŸ” æ–‡ä»¶å·®å¼‚æ¦‚è§ˆ:"
    git diff --cached --stat 2>/dev/null || echo "(æ–°æ–‡ä»¶æ— å·®å¼‚æ˜¾ç¤º)"
    echo ""
    echo "â­ï¸ ä¸‹ä¸€æ­¥æ“ä½œï¼š"
    echo " 1. æ£€æŸ¥åˆå¹¶ç»“æœ: git diff --cached"
    echo " 2. æ£€æŸ¥æ–°æ–‡ä»¶å†…å®¹ (å¦‚æœ‰): git diff --no-index /dev/null <æ–‡ä»¶å>"
    echo " 3. æäº¤æ›´æ”¹: git commit -m 'Batch merge for {assignee_name}: {len(assignee_groups)} groups, {len(all_files)} files'"
    echo " 4. æ¨é€åˆ†æ”¯: git push origin {batch_branch_name}"
    echo ""
    echo "ğŸ”„ å¦‚éœ€å›æ»š: git reset --hard HEAD"
else
    echo "âŒ æ‰¹é‡æ™ºèƒ½åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜"
    echo ""
    echo "ğŸ”§ å¯èƒ½çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼š"
    echo " 1. æŸäº›æ–‡ä»¶åœ¨æºåˆ†æ”¯ä¸­ä¸å­˜åœ¨ - è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œåˆ†æ”¯"
    echo " 2. æƒé™é—®é¢˜ - è¯·æ£€æŸ¥æ–‡ä»¶å’Œç›®å½•æƒé™"
    echo " 3. è·¯å¾„å†²çª - è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®"
    echo ""
    echo "ğŸ“Š å½“å‰çŠ¶æ€:"
    git status
    echo ""
    echo "ğŸ› ï¸ æ‰‹åŠ¨å¤„ç†æ­¥éª¤ï¼š"
    echo " 1. æ£€æŸ¥å…·ä½“é”™è¯¯ä¿¡æ¯ (è§ä¸Šæ–¹è¾“å‡º)"
    echo " 2. å¯¹äºé—®é¢˜æ–‡ä»¶ï¼Œæ‰‹åŠ¨å¤åˆ¶: cp source_branch_checkout/path target/path"
    echo " 3. æ·»åŠ æ–‡ä»¶: git add <files>"
    echo " 4. æäº¤: git commit -m 'Manual batch merge for {assignee_name}'"
    echo ""
    echo "ğŸ’¡ æç¤º: ä½ å¯ä»¥åˆ†ç»„å¤„ç†ï¼Œå…ˆå¤„ç†æˆåŠŸçš„æ–‡ä»¶ï¼Œå†å•ç‹¬å¤„ç†é—®é¢˜æ–‡ä»¶"
    exit 1
fi
"""

        script_file = self.work_dir / f"merge_batch_{assignee_name.replace(' ', '_')}.sh"
        with open(script_file, 'w') as f:
            f.write(script_content)

        os.chmod(script_file, 0o755)

        print(f"âœ… å·²ç”Ÿæˆæ™ºèƒ½æ‰¹é‡åˆå¹¶è„šæœ¬: {script_file}")
        print(f"ğŸ¯ è¯·æ‰§è¡Œ: ./{script_file}")

        return True

    def check_status(self):
        """æ£€æŸ¥åˆå¹¶çŠ¶æ€"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        print("ğŸ“Š æ™ºèƒ½åˆå¹¶çŠ¶æ€æ¦‚è§ˆ:")
        print(f"æºåˆ†æ”¯: {plan['source_branch']}")
        print(f"ç›®æ ‡åˆ†æ”¯: {plan['target_branch']}")
        print(f"é›†æˆåˆ†æ”¯: {plan['integration_branch']}")
        print(f"æ€»æ–‡ä»¶æ•°: {plan['total_files']}")
        print(f"æ¯ç»„æœ€å¤§æ–‡ä»¶æ•°: {plan.get('max_files_per_group', 5)}")
        print()

        assigned_count = 0
        completed_count = 0
        total_groups = len(plan["groups"])
        total_files_assigned = 0
        fallback_assigned = 0

        print("ğŸ“‹ æ™ºèƒ½åˆ†ç»„ä¸ä»»åŠ¡åˆ†é…çŠ¶æ€:")

        # ä¼˜åŒ–è¡¨æ ¼æ˜¾ç¤º
        headers = ["ç»„å", "æ–‡ä»¶æ•°", "è´Ÿè´£äºº", "çŠ¶æ€", "åˆ†é…ç±»å‹", "æ¨èç†ç”±"]
        widths = [30, 8, 20, 8, 12, 35]
        aligns = ['left', 'center', 'left', 'center', 'left', 'left']

        self._print_table_header(headers, widths, aligns)

        for group in plan["groups"]:
            status_icon = "âœ…" if group["status"] == "completed" else "ğŸ”„" if group.get("assignee") else "â³"
            assignee = group.get("assignee", "æœªåˆ†é…")
            file_count = group.get("file_count", len(group["files"]))

            # è·å–åˆ†é…ç±»å‹
            assignment_reason = group.get("assignment_reason", "æœªæŒ‡å®š")
            assignment_type = self._categorize_assignment_reason(assignment_reason)

            # è·å–æ¨èä¿¡æ¯
            recommended_info = "N/A"

            # æ£€æŸ¥æ˜¯å¦æ˜¯å¤‡é€‰åˆ†é…
            is_fallback = bool(group.get("fallback_reason", ""))
            if is_fallback:
                fallback_assigned += 1

            if assignee != "æœªåˆ†é…" and 'contributors' in group and group['contributors']:
                if assignee in group['contributors']:
                    contributor_stats = group['contributors'][assignee]
                    if isinstance(contributor_stats, dict):
                        recent_commits = contributor_stats.get('recent_commits', 0)
                        total_commits = contributor_stats.get('total_commits', 0)
                        score = contributor_stats.get('score', 0)
                        if is_fallback:
                            recommended_info = f"[å¤‡é€‰]{group['fallback_reason'][:15]}"
                        else:
                            recommended_info = f"å¾—åˆ†:{score}(è¿‘æœŸ:{recent_commits})"
                    else:
                        recommended_info = f"å†å²æäº¤:{contributor_stats}"
                elif 'contributors' in group and group['contributors']:
                    # æ˜¾ç¤ºæœ€æ¨èçš„è´¡çŒ®è€…
                    try:
                        best_contributor = max(group['contributors'].items(), key=lambda x: x[1]['score'] if isinstance(x[1], dict) else x[1])
                        contributor_name = best_contributor[0]
                        stats = best_contributor[1]
                        if isinstance(stats, dict):
                            recommended_info = f"æ¨è:{contributor_name}({stats['score']})"
                        else:
                            recommended_info = f"æ¨è:{contributor_name}({stats})"
                    except:
                        recommended_info = "åˆ†æä¸­..."

            values = [group['name'], str(file_count), assignee, status_icon, assignment_type, recommended_info]
            self._print_table_row(values, widths, aligns)

            if assignee != "æœªåˆ†é…":
                assigned_count += 1
                total_files_assigned += file_count
                if group["status"] == "completed":
                    completed_count += 1

        self._print_table_separator(widths)
        print(f"ğŸ“ˆ è¿›åº¦ç»Ÿè®¡: {assigned_count}/{total_groups} ç»„å·²åˆ†é… ({total_files_assigned}/{plan['total_files']} æ–‡ä»¶), {completed_count}/{total_groups} ç»„å·²å®Œæˆ")
        print(f"ğŸ”„ å¤‡é€‰åˆ†é…: {fallback_assigned} ç»„é€šè¿‡ç›®å½•åˆ†æåˆ†é…")

        if assigned_count < total_groups:
            unassigned = [g['name'] for g in plan['groups'] if not g.get('assignee')]
            print(f"\nâš ï¸ æœªåˆ†é…çš„ç»„: {', '.join(unassigned[:5])}" + ("..." if len(unassigned) > 5 else ""))

        # æ˜¾ç¤ºè´Ÿè½½åˆ†å¸ƒ
        assignee_workload = {}
        for group in plan["groups"]:
            assignee = group.get("assignee")
            if assignee and assignee != "æœªåˆ†é…":
                if assignee not in assignee_workload:
                    assignee_workload[assignee] = {"groups": 0, "files": 0, "completed": 0, "fallback": 0}
                assignee_workload[assignee]["groups"] += 1
                assignee_workload[assignee]["files"] += group.get("file_count", len(group["files"]))
                if group["status"] == "completed":
                    assignee_workload[assignee]["completed"] += 1
                if group.get("fallback_reason"):
                    assignee_workload[assignee]["fallback"] += 1

        if assignee_workload:
            print(f"\nğŸ‘¥ è´Ÿè½½åˆ†å¸ƒ:")
            for person, workload in sorted(assignee_workload.items(), key=lambda x: x[1]["files"], reverse=True):
                fallback_info = f"(å«{workload['fallback']}ä¸ªå¤‡é€‰)" if workload['fallback'] > 0 else ""
                print(f" {person}: {workload['completed']}/{workload['groups']} ç»„å®Œæˆ, {workload['files']} ä¸ªæ–‡ä»¶ {fallback_info}")

    def show_contributor_analysis(self):
        """æ˜¾ç¤ºè´¡çŒ®è€…åˆ†æï¼ˆé‡ç‚¹å…³æ³¨ä¸€å¹´å†…æ´»è·ƒåº¦ï¼‰"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        print("\nğŸ‘¥ æ™ºèƒ½è´¡çŒ®è€…åˆ†ææŠ¥å‘Š (é‡ç‚¹å…³æ³¨ä¸€å¹´å†…æ´»è·ƒåº¦):")
        print("=" * 90)
        print("ğŸ’¡ è¯„åˆ†è§„åˆ™ï¼šä¸€å¹´å†…æäº¤æ•° Ã— 3 + å†å²æ€»æäº¤æ•° Ã— 1")
        print("ğŸ¯ åˆ†é…ç­–ç•¥ï¼šä¼˜å…ˆåˆ†é…ç»™è¿‘æœŸæ´»è·ƒä¸”ç†Ÿæ‚‰ç›¸å…³æ–‡ä»¶çš„å¼€å‘è€…")
        print("ğŸš« è‡ªåŠ¨æ’é™¤ï¼šè¿‘3ä¸ªæœˆæ— æäº¤çš„äººå‘˜")

        # è·å–æ´»è·ƒè´¡çŒ®è€…ä¿¡æ¯
        active_contributors = self.get_active_contributors(3)
        all_contributors_global = {}

        for group in plan["groups"]:
            print(f"\nğŸ“ ç»„: {group['name']} ({group.get('file_count', len(group['files']))} æ–‡ä»¶)")

            assignee = group.get('assignee', 'æœªåˆ†é…')
            fallback_reason = group.get('fallback_reason', '')

            if assignee != 'æœªåˆ†é…':
                if fallback_reason:
                    print(f" å½“å‰åˆ†é…: {assignee} [å¤‡é€‰åˆ†é…: {fallback_reason}]")
                else:
                    print(f" å½“å‰åˆ†é…: {assignee}")
            else:
                print(f" å½“å‰åˆ†é…: æœªåˆ†é…")

            if 'contributors' in group and group['contributors']:
                print(" è´¡çŒ®è€…æ’å (ä¸€å¹´å†…|å†å²æ€»è®¡|ç»¼åˆå¾—åˆ†|æ´»è·ƒçŠ¶æ€):")
                sorted_contributors = sorted(
                    group['contributors'].items(),
                    key=lambda x: x[1]['score'] if isinstance(x[1], dict) else x[1],
                    reverse=True
                )
                for i, (author, stats) in enumerate(sorted_contributors[:3], 1):
                    if isinstance(stats, dict):
                        recent = stats['recent_commits']
                        total = stats['total_commits']
                        score = stats['score']

                        # æ´»è·ƒåº¦å’ŒçŠ¶æ€æ ‡è¯†
                        if author in active_contributors:
                            if recent >= 10:
                                activity = "ğŸ”¥æ´»è·ƒ"
                            elif recent >= 3:
                                activity = "ğŸ“ˆä¸­ç­‰"
                            elif recent >= 1:
                                activity = "ğŸ“Šä½ç­‰"
                            else:
                                activity = "ğŸ“Šè¿‘æœŸ"
                        else:
                            activity = "ğŸ’¤é™é»˜"

                        print(f" {i}. {author}: {recent}|{total}|{score} {activity}")
                    else:
                        activity = "ğŸ“Šå†å²" if author in active_contributors else "ğŸ’¤é™é»˜"
                        print(f" {i}. {author}: ?|{stats}|{stats} {activity}")

                    # ç»Ÿè®¡å…¨å±€è´¡çŒ®
                    if author not in all_contributors_global:
                        all_contributors_global[author] = {
                            'total_commits': 0,
                            'recent_commits': 0,
                            'score': 0,
                            'groups_contributed': 0,
                            'groups_assigned': [],
                            'is_active': author in active_contributors
                        }

                    if isinstance(stats, dict):
                        all_contributors_global[author]['recent_commits'] += stats['recent_commits']
                        all_contributors_global[author]['total_commits'] += stats['total_commits']
                        all_contributors_global[author]['score'] += stats['score']
                    else:
                        all_contributors_global[author]['total_commits'] += stats
                        all_contributors_global[author]['score'] += stats

                    all_contributors_global[author]['groups_contributed'] += 1

                    # æ£€æŸ¥æ˜¯å¦è¢«åˆ†é…åˆ°è¿™ä¸ªç»„
                    if group.get('assignee') == author:
                        all_contributors_global[author]['groups_assigned'].append(group['name'])
            else:
                print(" âš ï¸ è´¡çŒ®è€…æ•°æ®æœªåˆ†æï¼Œè¯·å…ˆè¿è¡Œè‡ªåŠ¨åˆ†é…ä»»åŠ¡")

        if all_contributors_global:
            print(f"\nğŸ† å…¨å±€è´¡çŒ®è€…æ™ºèƒ½æ’å (åŸºäºä¸€å¹´å†…æ´»è·ƒåº¦):")

            # ä¼˜åŒ–è¡¨æ ¼æ˜¾ç¤º
            headers = ["æ’å", "å§“å", "è¿‘æœŸ", "å†å²", "å¾—åˆ†", "æ´»è·ƒçŠ¶æ€", "å‚ä¸ç»„", "åˆ†é…ç»„", "è¿‘æœŸæ´»è·ƒ"]
            widths = [6, 20, 6, 6, 8, 10, 8, 8, 10]
            aligns = ['center', 'left', 'center', 'center', 'center', 'center', 'center', 'center', 'center']

            self._print_table_header(headers, widths, aligns)

            sorted_global = sorted(all_contributors_global.items(), key=lambda x: x[1]['score'], reverse=True)

            for i, (author, stats) in enumerate(sorted_global[:20], 1):
                recent = stats['recent_commits']
                total = stats['total_commits']
                score = stats['score']
                contributed = stats['groups_contributed']
                assigned = len(stats['groups_assigned'])
                is_active = stats['is_active']

                # æ´»è·ƒåº¦åˆ¤æ–­ (é‡ç‚¹å…³æ³¨è¿‘æœŸ)
                if not is_active:
                    activity = "ğŸ’¤é™é»˜"
                elif recent >= 15:
                    activity = "ğŸ”¥é«˜"
                elif recent >= 5:
                    activity = "ğŸ“ˆä¸­"
                elif recent >= 1:
                    activity = "ğŸ“Šä½"
                else:
                    activity = "ğŸ“Šè¿‘æœŸ"

                assigned_display = f"{assigned}ç»„" if assigned > 0 else "æ— "
                active_status = "âœ…" if is_active else "âŒ"

                values = [str(i), author, str(recent), str(total), str(score), activity, str(contributed), assigned_display, active_status]
                self._print_table_row(values, widths, aligns)

            print(f"\nğŸ“Š æ´»è·ƒåº¦è¯´æ˜ (åŸºäºä¸€å¹´å†…æäº¤ + è¿‘3ä¸ªæœˆæ´»è·ƒåº¦):")
            print("ğŸ”¥é«˜: 15+æ¬¡ ğŸ“ˆä¸­: 5-14æ¬¡ ğŸ“Šä½: 1-4æ¬¡ ğŸ“Šè¿‘æœŸ: è¿‘æœŸæœ‰æ´»åŠ¨ ğŸ’¤é™é»˜: è¿‘3ä¸ªæœˆæ— æäº¤")
            print("âœ…: è¿‘3ä¸ªæœˆæ´»è·ƒ âŒ: è¿‘3ä¸ªæœˆé™é»˜")
            print("\nğŸ¯ å»ºè®®: ä¼˜å…ˆå°†ä»»åŠ¡åˆ†é…ç»™âœ…ä¸”ğŸ”¥ğŸ“ˆçº§åˆ«çš„å¼€å‘è€…ï¼Œç¡®ä¿åˆå¹¶è´¨é‡å’Œæ•ˆç‡")
        else:
            print("\nâš ï¸ æš‚æ— è´¡çŒ®è€…æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œè‡ªåŠ¨åˆ†é…ä»»åŠ¡ä»¥åˆ†æè´¡çŒ®åº¦")

    def mark_group_completed(self, group_name):
        """æ ‡è®°æŒ‡å®šç»„ä¸ºå·²å®Œæˆ"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return False

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        # æ‰¾åˆ°å¯¹åº”ç»„
        group_found = False
        for group in plan["groups"]:
            if group["name"] == group_name:
                group_found = True
                old_status = group.get("status", "pending")
                group["status"] = "completed"
                group["completed_at"] = datetime.now().isoformat()

                assignee = group.get("assignee", "æœªåˆ†é…")
                file_count = group.get("file_count", len(group["files"]))

                print(f"âœ… ç»„ '{group_name}' å·²æ ‡è®°ä¸ºå®Œæˆ")
                print(f"   è´Ÿè´£äºº: {assignee}")
                print(f"   æ–‡ä»¶æ•°: {file_count}")
                print(f"   çŠ¶æ€å˜æ›´: {old_status} â†’ completed")
                break

        if not group_found:
            print(f"âŒ æœªæ‰¾åˆ°ç»„: {group_name}")
            return False

        # ä¿å­˜æ›´æ–°
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan, f, indent=2, ensure_ascii=False)

        # æ˜¾ç¤ºæ•´ä½“è¿›åº¦
        completed_count = sum(1 for g in plan["groups"] if g.get("status") == "completed")
        total_count = len(plan["groups"])
        print(f"ğŸ“Š æ•´ä½“è¿›åº¦: {completed_count}/{total_count} ç»„å·²å®Œæˆ ({completed_count/total_count*100:.1f}%)")

        return True

    def mark_assignee_completed(self, assignee_name):
        """æ ‡è®°æŒ‡å®šè´Ÿè´£äººçš„æ‰€æœ‰ä»»åŠ¡ä¸ºå·²å®Œæˆ"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return False

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        # æ‰¾åˆ°è´Ÿè´£äººçš„æ‰€æœ‰ä»»åŠ¡
        assignee_groups = []
        for group in plan["groups"]:
            if group.get("assignee", "").lower() == assignee_name.lower():
                assignee_groups.append(group)

        if not assignee_groups:
            print(f"âŒ è´Ÿè´£äºº '{assignee_name}' æ²¡æœ‰åˆ†é…çš„ä»»åŠ¡")
            return False

        # æ ‡è®°æ‰€æœ‰ä»»åŠ¡ä¸ºå®Œæˆ
        completion_time = datetime.now().isoformat()
        completed_count = 0

        for group in assignee_groups:
            if group.get("status") != "completed":
                group["status"] = "completed"
                group["completed_at"] = completion_time
                completed_count += 1

        # ä¿å­˜æ›´æ–°
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan, f, indent=2, ensure_ascii=False)

        total_files = sum(g.get("file_count", len(g["files"])) for g in assignee_groups)

        print(f"âœ… è´Ÿè´£äºº '{assignee_name}' çš„æ‰€æœ‰ä»»åŠ¡å·²æ ‡è®°å®Œæˆ")
        print(f"   å®Œæˆç»„æ•°: {completed_count}/{len(assignee_groups)}")
        print(f"   æ¶‰åŠæ–‡ä»¶: {total_files} ä¸ª")

        # æ˜¾ç¤ºæ•´ä½“è¿›åº¦
        all_completed_count = sum(1 for g in plan["groups"] if g.get("status") == "completed")
        total_count = len(plan["groups"])
        print(f"ğŸ“Š æ•´ä½“è¿›åº¦: {all_completed_count}/{total_count} ç»„å·²å®Œæˆ ({all_completed_count/total_count*100:.1f}%)")

        return True

    def auto_check_remote_status(self):
        """è‡ªåŠ¨æ£€æŸ¥è¿œç¨‹åˆ†æ”¯çŠ¶æ€ï¼Œæ¨æ–­å“ªäº›ç»„å¯èƒ½å·²å®Œæˆ"""
        plan_file = self.work_dir / "merge_plan.json"
        if not plan_file.exists():
            print("âŒ åˆå¹¶è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return False

        with open(plan_file, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        print("ğŸ” æ­£åœ¨æ£€æŸ¥è¿œç¨‹åˆ†æ”¯çŠ¶æ€...")

        # æ›´æ–°è¿œç¨‹åˆ†æ”¯ä¿¡æ¯
        self.run_git_command("git fetch --all")

        # è·å–æ‰€æœ‰è¿œç¨‹åˆ†æ”¯
        remote_branches_output = self.run_git_command("git branch -r")
        if not remote_branches_output:
            print("âš ï¸ æ— æ³•è·å–è¿œç¨‹åˆ†æ”¯ä¿¡æ¯")
            return False

        remote_branches = set()
        for line in remote_branches_output.split('\n'):
            branch = line.strip()
            if branch and not branch.startswith('origin/HEAD'):
                remote_branches.add(branch.replace('origin/', ''))

        print(f"ğŸ“¡ å‘ç° {len(remote_branches)} ä¸ªè¿œç¨‹åˆ†æ”¯")

        # æ£€æŸ¥æ¯ä¸ªç»„å¯¹åº”çš„è¿œç¨‹åˆ†æ”¯
        potentially_completed = []
        confirmed_completed = []

        for group in plan["groups"]:
            if group.get("status") == "completed":
                continue  # å·²ç»æ ‡è®°å®Œæˆçš„è·³è¿‡

            assignee = group.get("assignee")
            if not assignee:
                continue  # æœªåˆ†é…çš„è·³è¿‡

            group_name = group["name"]

            # ç”Ÿæˆå¯èƒ½çš„åˆ†æ”¯å
            possible_branch_names = [
                f"feat/merge-{group_name.replace('/', '-')}-{assignee.replace(' ', '-')}",
                f"feat/merge-batch-{assignee.replace(' ', '-')}"
            ]

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„è¿œç¨‹åˆ†æ”¯
            for branch_name in possible_branch_names:
                if any(branch_name in rb for rb in remote_branches):
                    potentially_completed.append({
                        "group": group,
                        "branch": branch_name,
                        "assignee": assignee
                    })
                    break

        if potentially_completed:
            print(f"\nğŸ¯ å‘ç° {len(potentially_completed)} ä¸ªå¯èƒ½å·²å®Œæˆçš„ç»„:")
            print("-" * 80)

            for item in potentially_completed:
                group = item["group"]
                branch = item["branch"]
                assignee = item["assignee"]
                file_count = group.get("file_count", len(group["files"]))

                print(f"ç»„: {group['name']:<25} è´Ÿè´£äºº: {assignee:<15} åˆ†æ”¯: {branch}")
                print(f"   æ–‡ä»¶æ•°: {file_count}")

                # è¯¢é—®æ˜¯å¦æ ‡è®°ä¸ºå®Œæˆ
                confirm = input(f"   æ˜¯å¦æ ‡è®°ä¸ºå®Œæˆ? (y/N): ").strip().lower()
                if confirm == 'y':
                    group["status"] = "completed"
                    group["completed_at"] = datetime.now().isoformat()
                    group["auto_detected"] = True
                    confirmed_completed.append(group['name'])
                    print(f"   âœ… å·²æ ‡è®°å®Œæˆ")
                else:
                    print(f"   â­ï¸ è·³è¿‡")
                print()

        # ä¿å­˜æ›´æ–°
        if confirmed_completed:
            with open(plan_file, 'w', encoding='utf-8') as f:
                json.dump(plan, f, indent=2, ensure_ascii=False)

            print(f"ğŸ“Š æœ¬æ¬¡è‡ªåŠ¨æ£€æŸ¥ç»“æœ:")
            print(f"   è‡ªåŠ¨æ ‡è®°å®Œæˆ: {len(confirmed_completed)} ä¸ªç»„")
            for group_name in confirmed_completed:
                print(f"   - {group_name}")

        # æ˜¾ç¤ºæ•´ä½“è¿›åº¦
        all_completed_count = sum(1 for g in plan["groups"] if g.get("status") == "completed")
        total_count = len(plan["groups"])
        print(f"\nğŸ“ˆ æ•´ä½“è¿›åº¦: {all_completed_count}/{total_count} ç»„å·²å®Œæˆ ({all_completed_count/total_count*100:.1f}%)")

        if potentially_completed and not confirmed_completed:
            print("\nğŸ’¡ æç¤º: å¦‚æœè¿™äº›åˆ†æ”¯ç¡®å®å¯¹åº”å·²å®Œæˆçš„åˆå¹¶ï¼Œå»ºè®®æ‰‹åŠ¨æ ‡è®°å®Œæˆ")

        return True

def main():
    if len(sys.argv) < 3:
        print("ä½¿ç”¨æ–¹æ³•: python git_merge_tool.py <source_branch> <target_branch> [max_files_per_group]")
        print("ç¤ºä¾‹: python git_merge_tool.py feature/big-feature main 5")
        sys.exit(1)

    source_branch = sys.argv[1]
    target_branch = sys.argv[2]
    max_files_per_group = int(sys.argv[3]) if len(sys.argv) > 3 else 5

    tool = GitMergeTool(source_branch, target_branch, max_files_per_group=max_files_per_group)

    print("ğŸš€ Gitå¤§åˆ†å‰æ™ºèƒ½åˆ†æ­¥åˆå¹¶å·¥å…· (å¢å¼ºç‰ˆ)")
    print(f"æºåˆ†æ”¯: {source_branch}")
    print(f"ç›®æ ‡åˆ†æ”¯: {target_branch}")
    print(f"æ¯ç»„æœ€å¤§æ–‡ä»¶æ•°: {max_files_per_group}")
    print()

    while True:
        print("\nğŸ“‹ å¯ç”¨æ“ä½œ:")
        print("1. åˆ†æåˆ†æ”¯åˆ†å‰")
        print("2. åˆ›å»ºæ™ºèƒ½åˆå¹¶è®¡åˆ’")
        print("3. æ™ºèƒ½è‡ªåŠ¨åˆ†é…ä»»åŠ¡ (å«æ´»è·ƒåº¦è¿‡æ»¤+å¤‡é€‰æ–¹æ¡ˆ)")
        print("4. æ‰‹åŠ¨åˆ†é…ä»»åŠ¡")
        print("5. æŸ¥çœ‹è´¡çŒ®è€…æ™ºèƒ½åˆ†æ")
        print("6. åˆå¹¶æŒ‡å®šç»„")
        print("7. æœç´¢è´Ÿè´£äººä»»åŠ¡")
        print("8. åˆå¹¶æŒ‡å®šè´Ÿè´£äººçš„æ‰€æœ‰ä»»åŠ¡")
        print("9. æ£€æŸ¥çŠ¶æ€")
        print("10. æŸ¥çœ‹åˆ†ç»„è¯¦ç»†ä¿¡æ¯")
        print("11. æŸ¥çœ‹åˆ†é…åŸå› åˆ†æ")
        print("12. å®ŒæˆçŠ¶æ€ç®¡ç† (æ ‡è®°å®Œæˆ/æ£€æŸ¥è¿œç¨‹çŠ¶æ€)")
        print("13. å®Œæˆæœ€ç»ˆåˆå¹¶")
        print("0. é€€å‡º")

        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (0-13): ").strip()

        if choice == '0':
            break
        elif choice == '1':
            tool.analyze_divergence()
        elif choice == '2':
            tool.create_merge_plan()
        elif choice == '3':
            print("ğŸ¤– æ™ºèƒ½è‡ªåŠ¨åˆ†é…æ¨¡å¼ (æ´»è·ƒåº¦è¿‡æ»¤+å¤‡é€‰æ–¹æ¡ˆ)")
            exclude_input = input("è¯·è¾“å…¥è¦æ’é™¤çš„ä½œè€…åˆ—è¡¨ (ç”¨é€—å·åˆ†éš”ï¼Œå›è½¦è·³è¿‡): ").strip()
            exclude_authors = [name.strip() for name in exclude_input.split(',')] if exclude_input else []

            max_tasks_input = input("æ¯äººæœ€å¤§ä»»åŠ¡æ•° (é»˜è®¤3): ").strip()
            max_tasks = int(max_tasks_input) if max_tasks_input.isdigit() else 3

            fallback_input = input("å¯ç”¨å¤‡é€‰åˆ†é…æ–¹æ¡ˆ? (Y/n): ").strip().lower()
            include_fallback = fallback_input != 'n'

            tool.auto_assign_tasks(exclude_authors, max_tasks, include_fallback)
        elif choice == '4':
            assignments = {}
            print("è¯·è¾“å…¥ä»»åŠ¡åˆ†é… (æ ¼å¼: ç»„å=è´Ÿè´£äººï¼Œè¾“å…¥ç©ºè¡Œç»“æŸ):")
            while True:
                line = input().strip()
                if not line:
                    break
                if '=' in line:
                    group, assignee = line.split('=', 1)
                    assignments[group.strip()] = assignee.strip()
            tool.assign_tasks(assignments)
        elif choice == '5':
            tool.show_contributor_analysis()
        elif choice == '6':
            group_name = input("è¯·è¾“å…¥è¦åˆå¹¶çš„ç»„å: ").strip()
            tool.merge_group(group_name)
        elif choice == '7':
            assignee_name = input("è¯·è¾“å…¥è´Ÿè´£äººå§“å: ").strip()
            tool.search_assignee_tasks(assignee_name)
        elif choice == '8':
            assignee_name = input("è¯·è¾“å…¥è¦åˆå¹¶ä»»åŠ¡çš„è´Ÿè´£äººå§“å: ").strip()
            tool.merge_assignee_tasks(assignee_name)
        elif choice == '9':
            tool.check_status()
        elif choice == '10':
            print("ğŸ“‹ æŸ¥çœ‹åˆ†ç»„è¯¦ç»†ä¿¡æ¯:")
            print("a. æŸ¥çœ‹æŒ‡å®šç»„è¯¦æƒ…")
            print("b. äº¤äº’å¼é€‰æ‹©æŸ¥çœ‹")
            print("c. è¿”å›ä¸»èœå•")

            sub_choice = input("è¯·é€‰æ‹©æ“ä½œ (a-c): ").strip().lower()
            if sub_choice == 'a':
                group_name = input("è¯·è¾“å…¥ç»„å: ").strip()
                tool.view_group_details(group_name)
            elif sub_choice == 'b':
                tool.view_group_details()
            elif sub_choice == 'c':
                continue
        elif choice == '11':
            tool.show_assignment_reasons()
        elif choice == '12':
            print("ğŸ“‹ å®ŒæˆçŠ¶æ€ç®¡ç†:")
            print("a. æ ‡è®°ç»„å®Œæˆ")
            print("b. æ ‡è®°è´Ÿè´£äººæ‰€æœ‰ä»»åŠ¡å®Œæˆ")
            print("c. è‡ªåŠ¨æ£€æŸ¥è¿œç¨‹åˆ†æ”¯çŠ¶æ€")
            print("d. è¿”å›ä¸»èœå•")

            sub_choice = input("è¯·é€‰æ‹©æ“ä½œ (a-d): ").strip().lower()
            if sub_choice == 'a':
                group_name = input("è¯·è¾“å…¥å·²å®Œæˆçš„ç»„å: ").strip()
                tool.mark_group_completed(group_name)
            elif sub_choice == 'b':
                assignee_name = input("è¯·è¾“å…¥è´Ÿè´£äººå§“å: ").strip()
                tool.mark_assignee_completed(assignee_name)
            elif sub_choice == 'c':
                tool.auto_check_remote_status()
            elif sub_choice == 'd':
                continue
        elif choice == '13':
            tool.finalize_merge()

if __name__ == "__main__":
    main()
