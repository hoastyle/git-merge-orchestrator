#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ä¼˜åŒ–æµ‹è¯•è„šæœ¬ - éªŒè¯v2.3ä¼˜åŒ–æ¶æ„çš„æ€§èƒ½æå‡
"""

import os
import sys
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from core.git_operations import GitOperations  
from core.enhanced_task_assigner import EnhancedTaskAssigner
from core.enhanced_contributor_analyzer import EnhancedContributorAnalyzer


def create_mock_plan_with_real_files(git_ops, num_files=100):
    """åˆ›å»ºåŒ…å«çœŸå®æ–‡ä»¶çš„æ¨¡æ‹Ÿè®¡åˆ’"""
    import subprocess
    import random
    
    try:
        # è·å–Gitä»“åº“ä¸­çš„çœŸå®æ–‡ä»¶åˆ—è¡¨
        result = subprocess.run(['git', 'ls-files'], 
                              capture_output=True, text=True, cwd='.')
        if result.returncode != 0:
            raise Exception("æ— æ³•è·å–Gitæ–‡ä»¶åˆ—è¡¨")
        
        all_files = [f.strip() for f in result.stdout.split('\n') if f.strip()]
        
        # è¿‡æ»¤Pythonæ–‡ä»¶å’Œå…¶ä»–ä»£ç æ–‡ä»¶
        code_files = [f for f in all_files if f.endswith(('.py', '.js', '.java', '.cpp', '.c', '.h'))]
        
        if len(code_files) < 10:
            # å¦‚æœä»£ç æ–‡ä»¶ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰æ–‡ä»¶
            code_files = all_files
        
        # éšæœºé€‰æ‹©æ–‡ä»¶ï¼ˆå¦‚æœæ–‡ä»¶æ•°é‡è¶³å¤Ÿï¼‰
        selected_files = code_files[:num_files] if len(code_files) >= num_files else code_files * ((num_files // len(code_files)) + 1)
        selected_files = selected_files[:num_files]
        
        # åˆ›å»ºæ–‡ä»¶è®¡åˆ’
        files = []
        for file_path in selected_files:
            files.append({
                'path': file_path,
                'status': 'pending', 
                'assignee': '',
                'assignment_reason': ''
            })
        
        return {
            'processing_mode': 'file_level',
            'files': files,
            'metadata': {
                'total_files': len(files),
                'real_files': len(code_files),
                'created': datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åˆ›å»ºçœŸå®æ–‡ä»¶è®¡åˆ’: {e}")
        # å›é€€åˆ°ä½¿ç”¨å®é™…å­˜åœ¨çš„æ ¸å¿ƒæ–‡ä»¶
        core_files = [
            'main.py',
            'core/git_operations.py',
            'core/enhanced_task_assigner.py',
            'core/enhanced_contributor_analyzer.py',
            'config.py',
            'git_merge_orchestrator.py'
        ]
        
        files = []
        for i, file_path in enumerate(core_files * (num_files // len(core_files) + 1)):
            if len(files) >= num_files:
                break
            files.append({
                'path': file_path,
                'status': 'pending',
                'assignee': '',
                'assignment_reason': ''
            })
        
        return {
            'processing_mode': 'file_level',
            'files': files[:num_files],
            'metadata': {
                'total_files': len(files[:num_files]),
                'created': datetime.now().isoformat(),
                'fallback': True
            }
        }


def test_performance_optimization():
    """æµ‹è¯•æ€§èƒ½ä¼˜åŒ–æ•ˆæœ"""
    print("ğŸš€ å¼€å§‹æ€§èƒ½ä¼˜åŒ–æµ‹è¯•...")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–Gitæ“ä½œ
        git_ops = GitOperations(".")
        print("âœ… Gitæ“ä½œæ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–å¢å¼ºä»»åŠ¡åˆ†é…å™¨
        enhanced_assigner = EnhancedTaskAssigner(git_ops)
        
        # æ£€æŸ¥å¢å¼ºåŠŸèƒ½æ˜¯å¦å¯ç”¨
        if not enhanced_assigner.is_enhanced_enabled():
            print("âŒ å¢å¼ºåŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return
        
        print(f"âœ… å¢å¼ºåŠŸèƒ½å·²å¯ç”¨")
        print(f"ğŸ“Š æµ‹è¯•é…ç½®:")
        print(f"  â€¢ æ¶æ„ç‰ˆæœ¬: v2.3 ä¼˜åŒ–æ¶æ„")
        print(f"  â€¢ å¤„ç†æ¨¡å¼: file_level")
        print(f"  â€¢ æµ‹è¯•æ–‡ä»¶æ•°: 100ä¸ªæ–‡ä»¶")
        print()
        
        # åˆ›å»ºæµ‹è¯•è®¡åˆ’ï¼ˆä½¿ç”¨çœŸå®æ–‡ä»¶ï¼‰
        print("ğŸ“ åˆ›å»ºæµ‹è¯•è®¡åˆ’...")
        test_plan = create_mock_plan_with_real_files(git_ops, 100)
        print(f"âœ… æµ‹è¯•è®¡åˆ’åˆ›å»ºå®Œæˆ: {len(test_plan['files'])} ä¸ªæ–‡ä»¶")
        if 'real_files' in test_plan['metadata']:
            print(f"ğŸ“ ä»“åº“ä¸­ä»£ç æ–‡ä»¶æ€»æ•°: {test_plan['metadata']['real_files']}")
        if 'fallback' in test_plan['metadata']:
            print("âš ï¸ ä½¿ç”¨æ ¸å¿ƒæ–‡ä»¶å›é€€æ¨¡å¼")
        print()
        
        # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
        print("âš¡ å¼€å§‹å¢å¼ºä»»åŠ¡åˆ†é…æ€§èƒ½æµ‹è¯•...")
        start_time = time.time()
        
        success_count, failed_count, assignment_stats = enhanced_assigner.enhanced_auto_assign_tasks(
            test_plan,
            exclude_authors=[],
            max_tasks_per_person=50,
            enable_line_analysis=True,
            include_fallback=True
        )
        
        total_time = time.time() - start_time
        
        print()
        print("=" * 60)
        print("ğŸ¯ æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"âœ… åˆ†é…æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
        print(f"âŒ åˆ†é…å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶") 
        print(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}s")
        print(f"ğŸ“Š å¹³å‡å¤„ç†æ—¶é—´: {(total_time / (success_count + failed_count)) * 1000:.1f}ms/æ–‡ä»¶")
        
        # æ˜¾ç¤ºæ¶æ„ç‰ˆæœ¬ä¿¡æ¯
        if 'architecture_version' in assignment_stats:
            print(f"ğŸ—ï¸  æ¶æ„ç‰ˆæœ¬: {assignment_stats['architecture_version']}")
        
        # æ˜¾ç¤ºæ€§èƒ½åˆ†è§£
        if 'performance_breakdown' in assignment_stats:
            breakdown = assignment_stats['performance_breakdown']
            print(f"ğŸ” æ€§èƒ½åˆ†è§£:")
            print(f"  â€¢ åˆ†æé˜¶æ®µ: {breakdown.get('analysis_time', 0):.2f}s")
            print(f"  â€¢ å†³ç­–è®¡ç®—: {breakdown.get('decision_time', 0):.2f}s")
            print(f"  â€¢ è´Ÿè½½å‡è¡¡: {breakdown.get('assignment_time', 0):.2f}s")
            print(f"  â€¢ ç»“æœåº”ç”¨: {breakdown.get('application_time', 0):.2f}s")
        
        # æ€§èƒ½è¯„ä¼°
        print()
        print("ğŸ“ˆ æ€§èƒ½è¯„ä¼°:")
        avg_time_ms = (total_time / (success_count + failed_count)) * 1000
        if avg_time_ms < 10:
            print(f"ğŸ† ä¼˜ç§€: å¹³å‡å¤„ç†æ—¶é—´ {avg_time_ms:.1f}ms/æ–‡ä»¶")
        elif avg_time_ms < 50:
            print(f"âœ… è‰¯å¥½: å¹³å‡å¤„ç†æ—¶é—´ {avg_time_ms:.1f}ms/æ–‡ä»¶")
        else:
            print(f"âš ï¸  éœ€è¦æ”¹è¿›: å¹³å‡å¤„ç†æ—¶é—´ {avg_time_ms:.1f}ms/æ–‡ä»¶")
        
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
        print()
        print("ğŸ“‹ æ€§èƒ½æ—¥å¿—:")
        log_files = [
            '.merge_work/enhanced_performance_log.json',
            '.merge_work/enhanced_analysis_performance.json', 
            '.merge_work/decision_performance.json',
            '.merge_work/load_balance_performance.json'
        ]
        
        for log_file in log_files:
            if Path(log_file).exists():
                print(f"âœ… {log_file} å·²ç”Ÿæˆ")
            else:
                print(f"âŒ {log_file} æœªç”Ÿæˆ")
        
        print()
        print("ğŸ‰ æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
        
        # æ€§èƒ½å¯¹æ¯”æç¤º
        print()
        print("ğŸ“Š æ€§èƒ½å¯¹æ¯”å‚è€ƒ:")
        print("  â€¢ ä¼˜åŒ–å‰ (v2.2): ~280-300ms/æ–‡ä»¶ (28.5s for 1000+ files)")
        print("  â€¢ ä¼˜åŒ–å (v2.3): <50ms/æ–‡ä»¶ (é¢„æœŸ90%+ æ€§èƒ½æå‡)")
        print("  â€¢ ç›®æ ‡æ€§èƒ½: <10ms/æ–‡ä»¶ (ä¼˜ç§€çº§åˆ«)")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_performance_optimization()