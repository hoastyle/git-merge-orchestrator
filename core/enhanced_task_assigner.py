"""
Git Merge Orchestrator - å¢å¼ºä»»åŠ¡åˆ†é…å™¨ï¼ˆv2.3ï¼‰
ç»“åˆå¢å¼ºçš„è´¡çŒ®è€…åˆ†æå™¨ï¼Œæ”¯æŒè¡Œæ•°æƒé‡åˆ†æçš„æ™ºèƒ½ä»»åŠ¡åˆ†é…
"""

from datetime import datetime
from config import (
    DEFAULT_MAX_TASKS_PER_PERSON,
    DEFAULT_ACTIVE_MONTHS,
    ENHANCED_CONTRIBUTOR_ANALYSIS,
)
from utils.performance_monitor import performance_monitor, global_performance_stats
from .enhanced_contributor_analyzer import EnhancedContributorAnalyzer


class EnhancedTaskAssigner:
    """å¢å¼ºçš„ä»»åŠ¡åˆ†é…å™¨ - æ”¯æŒå¤šç»´åº¦æƒé‡åˆ†æ"""

    def __init__(self, git_ops, fallback_assigner=None):
        self.git_ops = git_ops
        self.enhanced_analyzer = EnhancedContributorAnalyzer(git_ops)
        self.fallback_assigner = fallback_assigner  # å¯é€‰çš„å›é€€åˆ†é…å™¨

        # æ£€æŸ¥å¢å¼ºåŠŸèƒ½æ˜¯å¦å¯ç”¨
        self.enhanced_enabled = self.enhanced_analyzer.is_enabled()

        if not self.enhanced_enabled:
            print("âš ï¸  å¢å¼ºä»»åŠ¡åˆ†é…å™¨æœªå¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€åˆ†é…é€»è¾‘")

    def is_enhanced_enabled(self):
        """æ£€æŸ¥å¢å¼ºåŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        return self.enhanced_enabled

    @performance_monitor("å¢å¼ºæ™ºèƒ½ä»»åŠ¡åˆ†é…")
    def enhanced_auto_assign_tasks(
        self,
        plan,
        exclude_authors=None,
        max_tasks_per_person=None,
        enable_line_analysis=True,
        include_fallback=True,
    ):
        """
        å¢å¼ºçš„æ™ºèƒ½ä»»åŠ¡åˆ†é…
        
        Args:
            plan: åˆå¹¶è®¡åˆ’å¯¹è±¡
            exclude_authors: æ’é™¤çš„ä½œè€…åˆ—è¡¨
            max_tasks_per_person: æ¯äººæœ€å¤§ä»»åŠ¡æ•°
            enable_line_analysis: æ˜¯å¦å¯ç”¨è¡Œæ•°æƒé‡åˆ†æ
            include_fallback: æ˜¯å¦åŒ…å«å›é€€åˆ†é…
            
        Returns:
            tuple: (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡, åˆ†é…ç»Ÿè®¡)
        """
        exclude_authors = exclude_authors or []
        max_tasks_per_person = max_tasks_per_person or DEFAULT_MAX_TASKS_PER_PERSON
        start_time = datetime.now()

        print("ğŸš€ å¯åŠ¨å¢å¼ºæ™ºèƒ½ä»»åŠ¡åˆ†é…...")

        # æ£€æŸ¥åŠŸèƒ½çŠ¶æ€
        if not self.enhanced_enabled:
            print("âš ï¸  å¢å¼ºåŠŸèƒ½æœªå¯ç”¨ï¼Œä½¿ç”¨å›é€€åˆ†é…å™¨")
            if self.fallback_assigner:
                return self.fallback_assigner.turbo_auto_assign_tasks(
                    plan, exclude_authors, max_tasks_per_person, include_fallback
                )
            else:
                return self._basic_assignment_fallback(
                    plan, exclude_authors, max_tasks_per_person
                )

        # æ˜¾ç¤ºç®—æ³•ä¿¡æ¯
        algorithm_config = self.enhanced_analyzer.get_algorithm_config()
        algorithm_type = ENHANCED_CONTRIBUTOR_ANALYSIS.get(
            "assignment_algorithm", "comprehensive"
        )
        print(f"ğŸ§  ä½¿ç”¨ {algorithm_type} ç®—æ³•è¿›è¡Œæ™ºèƒ½åˆ†æ")
        print(f"âš¡ è¡Œæ•°æƒé‡åˆ†æ: {'å¯ç”¨' if enable_line_analysis else 'ç¦ç”¨'}")

        # ç‰¹æ€§è¯´æ˜
        features = []
        if algorithm_config.get("use_line_weight", False):
            features.append("è¡Œæ•°æƒé‡")
        if algorithm_config.get("use_time_weight", False):
            features.append("æ—¶é—´è¡°å‡")
        if algorithm_config.get("use_consistency_weight", False):
            features.append("ä¸€è‡´æ€§è¯„åˆ†")
        if algorithm_config.get("use_file_relationship", False):
            features.append("æ–‡ä»¶å…³è”")

        if features:
            print(f"ğŸ¯ å¯ç”¨ç‰¹æ€§: {', '.join(features)}")

        # è·å–æ´»è·ƒè´¡çŒ®è€…
        active_contributors = self.git_ops.get_active_contributors(
            DEFAULT_ACTIVE_MONTHS
        )

        # å¤„ç†ä¸åŒçš„å¤„ç†æ¨¡å¼ï¼ˆå…¼å®¹å­—å…¸å’Œå¯¹è±¡ï¼‰
        if isinstance(plan, dict):
            processing_mode = plan.get("processing_mode", "file_level")
        else:
            processing_mode = getattr(plan, "processing_mode", "file_level")

        if processing_mode == "file_level":
            return self._assign_file_level_enhanced(
                plan,
                exclude_authors,
                max_tasks_per_person,
                enable_line_analysis,
                active_contributors,
                start_time,
                include_fallback,
            )
        else:
            return self._assign_group_level_enhanced(
                plan,
                exclude_authors,
                max_tasks_per_person,
                enable_line_analysis,
                active_contributors,
                start_time,
                include_fallback,
            )

    def _assign_file_level_enhanced(
        self,
        plan,
        exclude_authors,
        max_tasks_per_person,
        enable_line_analysis,
        active_contributors,
        start_time,
        include_fallback=True,
    ):
        """æ–‡ä»¶çº§å¢å¼ºåˆ†é…"""
        # å…¼å®¹å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ•°æ®ç»“æ„
        if isinstance(plan, dict):
            files = plan.get("files", [])
        else:
            files = getattr(plan, "files", [])
            
        if not files:
            print("âŒ æ— æ–‡ä»¶éœ€è¦åˆ†é…")
            return 0, 0, {}

        print(f"ğŸ“ å‡†å¤‡åˆ†é… {len(files)} ä¸ªæ–‡ä»¶...")

        # æå–æ–‡ä»¶è·¯å¾„
        file_paths = [file_info.get("path", "") for file_info in files]
        file_paths = [path for path in file_paths if path]

        if not file_paths:
            print("âŒ æ— æœ‰æ•ˆæ–‡ä»¶è·¯å¾„")
            return 0, 0, {}

        # æ‰¹é‡åˆ†ææ–‡ä»¶è´¡çŒ®è€…
        from datetime import datetime
        analysis_start = datetime.now()
        print(f"ğŸ” æ­£åœ¨è¿›è¡Œæ‰¹é‡å¢å¼ºè´¡çŒ®è€…åˆ†æ... ({len(file_paths)} ä¸ªæ–‡ä»¶)")
        print("âš¡ å¯ç”¨ç‰¹æ€§: è¡Œæ•°æƒé‡ã€æ—¶é—´è¡°å‡ã€ä¸€è‡´æ€§è¯„åˆ†")
        
        batch_contributors = self.enhanced_analyzer.analyze_contributors_batch(
            file_paths, enable_line_analysis=enable_line_analysis
        )
        
        analysis_time = (datetime.now() - analysis_start).total_seconds()
        print(f"âœ… å¢å¼ºè´¡çŒ®è€…åˆ†æå®Œæˆ: {analysis_time:.2f}s ({analysis_time/len(file_paths)*1000:.1f}ms/æ–‡ä»¶)")

        # æ‰§è¡Œæ–‡ä»¶åˆ†é…
        assignment_start = datetime.now()
        print(f"ğŸ‘¥ å¼€å§‹æ–‡ä»¶åˆ†é…é€é’€...")
        success_count = 0
        failed_count = 0
        assignment_stats = {
            "total_files": len(files),
            "analyzed_files": len(batch_contributors),
            "active_contributors": len(active_contributors),
            "assignment_reasons": {},
            "algorithm_type": ENHANCED_CONTRIBUTOR_ANALYSIS.get(
                "assignment_algorithm", "comprehensive"
            ),
        }

        # è·Ÿè¸ªæ¯äººçš„ä»»åŠ¡æ•°
        person_task_count = {}

        for file_info in files:
            file_path = file_info.get("path", "")
            if not file_path:
                failed_count += 1
                continue

            contributors = batch_contributors.get(file_path, {})

            # è·å–æœ€ä½³åˆ†é…å¯¹è±¡
            best_author, author_info, reason = self.enhanced_analyzer.get_best_assignee(
                contributors, exclude_inactive=True
            )

            if not best_author or best_author in exclude_authors:
                # å°è¯•å›é€€åˆ†é…
                if include_fallback:
                    best_author, reason = self._fallback_assignment(
                        file_path, exclude_authors
                    )

                if not best_author:
                    file_info["assignee"] = "æœªåˆ†é…"
                    file_info["status"] = "pending"
                    file_info["assignment_reason"] = "æ— å¯ç”¨è´¡çŒ®è€…"
                    failed_count += 1
                    continue

            # æ£€æŸ¥ä»»åŠ¡æ•°é‡é™åˆ¶
            current_tasks = person_task_count.get(best_author, 0)
            if current_tasks >= max_tasks_per_person:
                # å¯»æ‰¾æ›¿ä»£åˆ†é…
                alternative_assigned = self._find_alternative_assignee(
                    contributors,
                    exclude_authors,
                    person_task_count,
                    max_tasks_per_person,
                )

                if alternative_assigned:
                    best_author, reason = alternative_assigned
                else:
                    file_info["assignee"] = "æœªåˆ†é…"
                    file_info["status"] = "pending"
                    file_info["assignment_reason"] = "è¶…å‡ºä»»åŠ¡é™é¢"
                    failed_count += 1
                    continue

            # æ‰§è¡Œåˆ†é…
            file_info["assignee"] = best_author
            file_info["status"] = "assigned"
            file_info["assignment_reason"] = reason

            # æ›´æ–°ç»Ÿè®¡
            person_task_count[best_author] = person_task_count.get(best_author, 0) + 1
            assignment_stats["assignment_reasons"][file_path] = reason
            success_count += 1

        # åˆ†é…å®Œæˆç»Ÿè®¡å’Œæ€§èƒ½è®°å½•
        elapsed = (datetime.now() - start_time).total_seconds()
        assignment_time = (datetime.now() - assignment_start).total_seconds()
        
        # æ„å»ºæ€§èƒ½è®°å½•
        perf_log = {
            'analysis_phase': analysis_time,
            'assignment_phase': assignment_time,
            'total_execution_time': elapsed,
            'files_processed': len([f for f in files if not f.get("assignee", "").strip()]),
            'success_count': success_count,
            'failed_count': failed_count,
            'contributors_count': len(person_task_count),
            'avg_time_per_file_ms': (assignment_time / max(success_count + failed_count, 1)) * 1000
        }
        
        # ä¿å­˜æ€§èƒ½æ—¥å¿—
        self._save_enhanced_performance_log(perf_log)

        print(f"\nâœ… å¢å¼ºä»»åŠ¡åˆ†é…å®Œæˆ!")
        print(f"ğŸ“Š åˆ†é…ç»Ÿè®¡: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}, ç”¨æ—¶ {elapsed:.2f}s")
        print(f"ğŸ‘¥ æ¶‰åŠ {len(person_task_count)} ä½è´¡çŒ®è€…")
        
        # æ€§èƒ½åˆ†ææç¤º - å¸®åŠ©ç”¨æˆ·ç†è§£é‚£ä¸ª28ç§’
        if elapsed > 20:
            print(f"\nğŸ” æ€§èƒ½åˆ†æ (æ€»æ—¶é—´ {elapsed:.1f}s):")
            print(f"  ğŸ§ª åˆ†æé˜¶æ®µ: {analysis_time:.1f}s")
            print(f"  ğŸ‘¥ åˆ†é…é˜¶æ®µ: {assignment_time:.1f}s")
            print(f"  ğŸ“¦ å…¶ä»–å¤„ç†: {elapsed - analysis_time - assignment_time:.1f}s")
            
            # æ€§èƒ½å»ºè®®
            if assignment_time > analysis_time * 1.5:
                print(f"  ğŸ’¡ å»ºè®®: åˆ†é…é€»è¾‘è€—æ—¶è¾ƒå¤šï¼Œå¯è€ƒè™‘ä¼˜åŒ–ç®—æ³•")
            if elapsed - analysis_time - assignment_time > 5:
                print(f"  ğŸ’¡ å»ºè®®: å…¶ä»–å¤„ç†è€—æ—¶è¾ƒå¤šï¼Œæ£€æŸ¥I/Oæ“ä½œæˆ–ç¼“å­˜")

        # æ˜¾ç¤ºè´Ÿè½½åˆ†å¸ƒ
        self._show_workload_distribution(person_task_count)

        assignment_stats.update(
            {
                "success_count": success_count,
                "failed_count": failed_count,
                "elapsed_time": elapsed,
                "contributors_involved": len(person_task_count),
                "workload_distribution": person_task_count,
            }
        )

        return success_count, failed_count, assignment_stats

    def _assign_group_level_enhanced(
        self,
        plan,
        exclude_authors,
        max_tasks_per_person,
        enable_line_analysis,
        active_contributors,
        start_time,
        include_fallback=True,
    ):
        """ç»„çº§å¢å¼ºåˆ†é…ï¼ˆå‘åå…¼å®¹ï¼‰"""
        # å…¼å®¹å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ•°æ®ç»“æ„
        if isinstance(plan, dict):
            groups = plan.get("groups", [])
        else:
            groups = getattr(plan, "groups", [])
            
        if not groups:
            print("âŒ æ— åˆ†ç»„éœ€è¦åˆ†é…")
            return 0, 0, {}

        print(f"ğŸ“ å‡†å¤‡åˆ†é… {len(groups)} ä¸ªç»„...")

        success_count = 0
        failed_count = 0
        assignment_stats = {
            "total_groups": len(groups),
            "active_contributors": len(active_contributors),
            "assignment_reasons": {},
            "algorithm_type": ENHANCED_CONTRIBUTOR_ANALYSIS.get(
                "assignment_algorithm", "comprehensive"
            ),
        }

        person_task_count = {}

        for group in groups:
            group_name = group.get("name", "")
            group_files = group.get("files", [])

            if not group_files:
                failed_count += 1
                continue

            # åˆ†æç»„å†…æ–‡ä»¶çš„è´¡çŒ®è€…
            print(f"ğŸ” åˆ†æç»„ {group_name}: {len(group_files)} ä¸ªæ–‡ä»¶...")
            batch_contributors = self.enhanced_analyzer.analyze_contributors_batch(
                group_files, enable_line_analysis=enable_line_analysis
            )

            # åˆå¹¶ç»„çº§è´¡çŒ®è€…ç»Ÿè®¡
            group_contributors = self._merge_group_contributors(batch_contributors)

            # è·å–æœ€ä½³åˆ†é…å¯¹è±¡
            best_author, author_info, reason = self.enhanced_analyzer.get_best_assignee(
                group_contributors, exclude_inactive=True
            )

            if not best_author or best_author in exclude_authors:
                if include_fallback:
                    best_author, reason = self._fallback_group_assignment(
                        group_name, exclude_authors
                    )

                if not best_author:
                    group["assignee"] = "æœªåˆ†é…"
                    group["status"] = "pending"
                    group["assignment_reason"] = "æ— å¯ç”¨è´¡çŒ®è€…"
                    failed_count += 1
                    continue

            # æ£€æŸ¥ä»»åŠ¡æ•°é‡é™åˆ¶
            current_tasks = person_task_count.get(best_author, 0)
            if current_tasks >= max_tasks_per_person:
                alternative_assigned = self._find_alternative_assignee(
                    group_contributors,
                    exclude_authors,
                    person_task_count,
                    max_tasks_per_person,
                )

                if alternative_assigned:
                    best_author, reason = alternative_assigned
                else:
                    group["assignee"] = "æœªåˆ†é…"
                    group["status"] = "pending"
                    group["assignment_reason"] = "è¶…å‡ºä»»åŠ¡é™é¢"
                    failed_count += 1
                    continue

            # æ‰§è¡Œåˆ†é…
            group["assignee"] = best_author
            group["status"] = "assigned"
            group["assignment_reason"] = reason

            person_task_count[best_author] = person_task_count.get(best_author, 0) + 1
            assignment_stats["assignment_reasons"][group_name] = reason
            success_count += 1

        # å®Œæˆç»Ÿè®¡
        elapsed = (datetime.now() - start_time).total_seconds()

        print(f"\nâœ… å¢å¼ºç»„çº§ä»»åŠ¡åˆ†é…å®Œæˆ!")
        print(f"ğŸ“Š åˆ†é…ç»Ÿè®¡: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}, ç”¨æ—¶ {elapsed:.2f}s")
        print(f"ğŸ‘¥ æ¶‰åŠ {len(person_task_count)} ä½è´¡çŒ®è€…")

        self._show_workload_distribution(person_task_count)

        assignment_stats.update(
            {
                "success_count": success_count,
                "failed_count": failed_count,
                "elapsed_time": elapsed,
                "contributors_involved": len(person_task_count),
                "workload_distribution": person_task_count,
            }
        )

        return success_count, failed_count, assignment_stats

    def _merge_group_contributors(self, batch_contributors):
        """åˆå¹¶ç»„å†…æ–‡ä»¶çš„è´¡çŒ®è€…ç»Ÿè®¡"""
        merged_contributors = {}

        for file_path, contributors in batch_contributors.items():
            for author, info in contributors.items():
                if author not in merged_contributors:
                    merged_contributors[author] = {
                        "total_commits": 0,
                        "recent_commits": 0,
                        "total_changes": 0,
                        "total_additions": 0,
                        "total_deletions": 0,
                        "score": 0,
                        "enhanced_score": 0,
                        "files_contributed": [],
                    }

                # åˆå¹¶ç»Ÿè®¡
                merged = merged_contributors[author]
                merged["total_commits"] += info.get("total_commits", 0)
                merged["recent_commits"] += info.get("recent_commits", 0)
                merged["total_changes"] += info.get("total_changes", 0)
                merged["total_additions"] += info.get("total_additions", 0)
                merged["total_deletions"] += info.get("total_deletions", 0)
                merged["enhanced_score"] += info.get("enhanced_score", 0)
                merged["files_contributed"].append(file_path)

        return merged_contributors

    def _find_alternative_assignee(
        self, contributors, exclude_authors, person_task_count, max_tasks
    ):
        """å¯»æ‰¾æ›¿ä»£åˆ†é…å¯¹è±¡"""
        ranking = self.enhanced_analyzer.get_contributor_ranking(contributors)

        for author, info in ranking:
            if (
                author not in exclude_authors
                and person_task_count.get(author, 0) < max_tasks
            ):
                reason = (
                    self.enhanced_analyzer._generate_assignment_reason(author, info)
                    + "ï¼ˆè´Ÿè½½å‡è¡¡åˆ†é…ï¼‰"
                )
                return (author, reason)

        return None

    def _fallback_assignment(self, file_path, exclude_authors):
        """å•æ–‡ä»¶å›é€€åˆ†é…"""
        # å°è¯•ç›®å½•çº§åˆ†æ
        import os

        directory = os.path.dirname(file_path)

        if directory:
            dir_contributors = self.git_ops.get_directory_contributors(directory)
            if dir_contributors:
                # è·å–æœ€é«˜åˆ†ä¸”ä¸åœ¨æ’é™¤åˆ—è¡¨çš„è´¡çŒ®è€…
                sorted_contributors = sorted(
                    dir_contributors.items(),
                    key=lambda x: x[1].get("score", 0),
                    reverse=True,
                )

                for author, info in sorted_contributors:
                    if author not in exclude_authors:
                        return author, "ç›®å½•çº§å›é€€åˆ†é…"

        return None, "å›é€€åˆ†é…å¤±è´¥"

    def _fallback_group_assignment(self, group_name, exclude_authors):
        """ç»„çº§å›é€€åˆ†é…"""
        # ä½¿ç”¨ç»„åä½œä¸ºè·¯å¾„è¿›è¡Œç›®å½•çº§åˆ†æ
        dir_contributors = self.git_ops.get_directory_contributors(group_name)
        if dir_contributors:
            sorted_contributors = sorted(
                dir_contributors.items(),
                key=lambda x: x[1].get("score", 0),
                reverse=True,
            )

            for author, info in sorted_contributors:
                if author not in exclude_authors:
                    return author, "ç»„çº§å›é€€åˆ†é…"

        return None, "å›é€€åˆ†é…å¤±è´¥"

    def _show_workload_distribution(self, person_task_count):
        """æ˜¾ç¤ºå·¥ä½œè´Ÿè½½åˆ†å¸ƒ"""
        if not person_task_count:
            return

        print("\nğŸ‘¥ å·¥ä½œè´Ÿè½½åˆ†å¸ƒ:")
        sorted_workload = sorted(
            person_task_count.items(), key=lambda x: x[1], reverse=True
        )

        for author, count in sorted_workload[:10]:  # åªæ˜¾ç¤ºå‰10å
            print(f"  ğŸ“‹ {author}: {count} ä¸ªä»»åŠ¡")

        if len(sorted_workload) > 10:
            print(f"  ... å¦å¤– {len(sorted_workload) - 10} ä½è´¡çŒ®è€…")

    def _basic_assignment_fallback(self, plan, exclude_authors, max_tasks_per_person):
        """åŸºç¡€åˆ†é…å›é€€ï¼ˆå½“å¢å¼ºåŠŸèƒ½ä¸å¯ç”¨æ—¶ï¼‰"""
        print("âš ï¸  ä½¿ç”¨åŸºç¡€åˆ†é…é€»è¾‘")

        # è¿™é‡Œå¯ä»¥è°ƒç”¨åŸæœ‰çš„åŸºç¡€åˆ†é…é€»è¾‘
        # æˆ–è€…è¿”å›æœ€å°åŒ–çš„åˆ†é…ç»“æœ

        # å…¼å®¹å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ•°æ®ç»“æ„
        if isinstance(plan, dict):
            processing_mode = plan.get("processing_mode", "file_level")
            items = plan.get("files" if processing_mode == "file_level" else "groups", [])
        else:
            processing_mode = getattr(plan, "processing_mode", "file_level")
            items = getattr(plan, "files" if processing_mode == "file_level" else "groups", [])

        # ç®€å•çš„è½®è¯¢åˆ†é…
        active_contributors = self.git_ops.get_active_contributors(
            DEFAULT_ACTIVE_MONTHS
        )
        available_contributors = [
            c for c in active_contributors if c not in exclude_authors
        ]

        if not available_contributors:
            return 0, len(items), {"error": "æ— å¯ç”¨è´¡çŒ®è€…"}

        success_count = 0
        for i, item in enumerate(items):
            assignee = available_contributors[i % len(available_contributors)]
            item["assignee"] = assignee
            item["status"] = "assigned"
            item["assignment_reason"] = "åŸºç¡€è½®è¯¢åˆ†é…"
            success_count += 1

        return (
            success_count,
            0,
            {"basic_assignment": True, "contributors": len(available_contributors)},
        )

    def get_assignment_analysis_report(self, plan):
        """è·å–åˆ†é…åˆ†ææŠ¥å‘Š"""
        # å…¼å®¹å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ•°æ®ç»“æ„
        if isinstance(plan, dict):
            processing_mode = plan.get("processing_mode", "file_level")
            items = plan.get("files" if processing_mode == "file_level" else "groups", [])
        else:
            processing_mode = getattr(plan, "processing_mode", "file_level")
            items = getattr(plan, "files" if processing_mode == "file_level" else "groups", [])

        report = {
            "total_items": len(items),
            "assigned_items": 0,
            "unassigned_items": 0,
            "contributors_involved": set(),
            "assignment_reasons": {},
            "enhanced_analysis_used": self.enhanced_enabled,
        }

        for item in items:
            assignee = item.get("assignee")
            if assignee and assignee != "æœªåˆ†é…":
                report["assigned_items"] += 1
                report["contributors_involved"].add(assignee)
            else:
                report["unassigned_items"] += 1

            reason = item.get("assignment_reason", "unknown")
            report["assignment_reasons"][reason] = (
                report["assignment_reasons"].get(reason, 0) + 1
            )

        report["contributors_involved"] = len(report["contributors_involved"])

        return report
        
    def _save_enhanced_performance_log(self, perf_log):
        """ä¿å­˜å¢å¼ºä»»åŠ¡åˆ†é…å™¨çš„è¯¦ç»†æ€§èƒ½æ—¥å¿—"""
        try:
            import json
            from pathlib import Path
            from datetime import datetime
            
            # è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
            if hasattr(self.git_ops, 'repo_path'):
                repo_path = Path(self.git_ops.repo_path)
            else:
                repo_path = Path(".")
                
            log_file = repo_path / ".merge_work" / "enhanced_performance_log.json"
            log_file.parent.mkdir(exist_ok=True)
            
            # æ„å»ºæ—¥å¿—æ¡ç›®
            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'component': 'EnhancedTaskAssigner',
                'version': '2.3',
                'performance_breakdown': perf_log,
                'summary': {
                    'total_time': perf_log.get('total_execution_time', 0),
                    'analysis_time': perf_log.get('analysis_phase', 0),
                    'assignment_time': perf_log.get('total_assignment_loop_time', 0),
                    'files_processed': perf_log.get('files_processed', 0),
                    'success_rate': perf_log.get('success_count', 0) / max(perf_log.get('files_processed', 1), 1) * 100,
                    'avg_time_per_file_ms': perf_log.get('avg_time_per_file_ms', 0)
                },
                'performance_insights': self._generate_performance_insights(perf_log)
            }
            
            # åŠ è½½ç°æœ‰æ—¥å¿—
            logs = []
            if log_file.exists():
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        logs = json.load(f)
                except:
                    logs = []
            
            # æ·»åŠ æ–°æ—¥å¿—
            logs.append(log_entry)
            
            # ä¿æŒæœ€è¿‘50æ¡è®°å½•
            if len(logs) > 50:
                logs = logs[-50:]
                
            # å†™å…¥æ–‡ä»¶
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, indent=2, ensure_ascii=False)
                
            print(f"ğŸ“‹ æ€§èƒ½æ—¥å¿—å·²ä¿å­˜: {log_file}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ€§èƒ½æ—¥å¿—å¤±è´¥: {e}")
    
    def _generate_performance_insights(self, perf_log):
        """ç”Ÿæˆæ€§èƒ½æ´å¯Ÿå»ºè®®"""
        insights = []
        
        total_time = perf_log.get('total_execution_time', 0)
        analysis_time = perf_log.get('analysis_phase', 0)
        assignment_time = perf_log.get('total_assignment_loop_time', 0)
        
        # åˆ†æå„é˜¶æ®µè€—æ—¶
        if total_time > 30:
            insights.append(f"æ€»è€—æ—¶è¾ƒé•¿ ({total_time:.1f}s), éœ€è¦ä¼˜åŒ–")
            
        if assignment_time > analysis_time * 1.5:
            insights.append(f"åˆ†é…é€»è¾‘è€—æ—¶è¾ƒå¤š ({assignment_time:.1f}s vs {analysis_time:.1f}s), å¯è€ƒè™‘ç®—æ³•ä¼˜åŒ–")
            
        if perf_log.get('total_decision_time', 0) > assignment_time * 0.4:
            insights.append("å†³ç­–è®¡ç®—è€—æ—¶è¾ƒå¤š, å¯è€ƒè™‘ç¼“å­˜ä¼˜åŒ–")
            
        if perf_log.get('fallback_operations', 0) > assignment_time * 0.2:
            insights.append("å›é€€æ“ä½œé¢‘ç¹, å¯è€ƒè™‘ä¼˜åŒ–ä¸»è¦åˆ†é…ç®—æ³•")
            
        avg_time = perf_log.get('avg_time_per_file_ms', 0)
        if avg_time > 50:  # 50ms per file
            insights.append(f"å¹³å‡æ–‡ä»¶å¤„ç†æ—¶é—´è¾ƒé•¿ ({avg_time:.1f}ms), å¯è€ƒè™‘æ‰¹é‡ä¼˜åŒ–")
            
        if not insights:
            insights.append("æ€§èƒ½è¡¨ç°è‰¯å¥½")
            
        return insights
