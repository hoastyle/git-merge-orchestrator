"""
Git Merge Orchestrator - æ–‡ä»¶çº§ä»»åŠ¡åˆ†é…å™¨
åŸºäºæ–‡ä»¶è´¡çŒ®åº¦åˆ†æè¿›è¡Œç²¾ç¡®çš„æ–‡ä»¶çº§ä»»åŠ¡åˆ†é…ï¼Œæ›¿ä»£åŸæœ‰çš„ç»„åˆ†é…ç³»ç»Ÿ
"""

from datetime import datetime, timedelta
from collections import defaultdict
import json
from pathlib import Path
from utils.progress_indicator import ProgressTracker, ProgressIndicator


class FileTaskAssigner:
    """æ–‡ä»¶çº§ä»»åŠ¡åˆ†é…å™¨ - åŸºäºè´¡çŒ®åº¦åˆ†æçš„æ™ºèƒ½æ–‡ä»¶åˆ†é…"""

    def __init__(self, contributor_analyzer, file_manager):
        self.contributor_analyzer = contributor_analyzer
        self.file_manager = file_manager

    def auto_assign_files(
        self, exclude_authors=None, max_tasks_per_person=200, include_fallback=True
    ):
        """æ™ºèƒ½è‡ªåŠ¨åˆ†é…æ–‡ä»¶ç»™è´¡çŒ®è€…"""
        # æ€§èƒ½ç›‘æ§å¼€å§‹
        main_start = datetime.now()
        print(f"ğŸš€ [PERF] å¼€å§‹æ–‡ä»¶ä»»åŠ¡åˆ†é…... (å¼€å§‹æ—¶é—´: {main_start.timestamp():.3f})")
        
        file_plan = self.file_manager.load_file_plan()
        if not file_plan:
            print("âŒ æ–‡ä»¶çº§è®¡åˆ’ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºåˆå¹¶è®¡åˆ’")
            return None

        total_files = len(file_plan["files"])

        steps = ["è·å–æ´»è·ƒè´¡çŒ®è€…", "åˆ†ææ–‡ä»¶è´¡çŒ®åº¦", "æ™ºèƒ½åˆ†é…æ–‡ä»¶", "ä¿å­˜åˆ†é…ç»“æœ"]
        tracker = ProgressTracker(len(steps), "æ–‡ä»¶ä»»åŠ¡åˆ†é…")

        # æ­¥éª¤ 1: è·å–æ´»è·ƒè´¡çŒ®è€…
        step1_start = datetime.now()
        tracker.step("è·å–æ´»è·ƒè´¡çŒ®è€…")
        exclude_authors = exclude_authors or []
        active_contributors = self.contributor_analyzer.get_active_contributors(3)

        step1_time = (datetime.now() - step1_start).total_seconds()
        print(f"â±ï¸  [PERF] æ­¥éª¤1-è·å–æ´»è·ƒè´¡çŒ®è€…: {step1_time:.3f}s")
        print(f"   ğŸ¯ æ´»è·ƒè´¡çŒ®è€…: {len(active_contributors)} ä½")
        print(f"   ğŸš« æ‰‹åŠ¨æ’é™¤: {len(exclude_authors)} ä½")

        # æ­¥éª¤ 2: åˆ†ææ–‡ä»¶è´¡çŒ®åº¦ï¼ˆä½¿ç”¨æ‰¹é‡åˆ†æä¼˜åŒ–ï¼‰
        tracker.step(f"åˆ†ææ–‡ä»¶è´¡çŒ®åº¦")
        
        unassigned_files = [f for f in file_plan["files"] if not f.get("assignee")]
        
        # ğŸš€ ä½¿ç”¨æ‰¹é‡åˆ†ææ›¿ä»£é€ä¸ªæ–‡ä»¶åˆ†æ
        print(f"ğŸš€ [PERF] ä½¿ç”¨æ‰¹é‡åˆ†æä¼˜åŒ– {len(unassigned_files)} ä¸ªæ–‡ä»¶...")
        batch_start = datetime.now()
        
        # æå–æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        file_paths = [f["path"] for f in unassigned_files]
        
        # æ‰¹é‡åˆ†ææ‰€æœ‰æ–‡ä»¶
        batch_contributors = self.contributor_analyzer.batch_analyze_all_files(file_paths)
        
        batch_time = (datetime.now() - batch_start).total_seconds()
        print(f"âœ… [PERF] æ‰¹é‡åˆ†æå®Œæˆ: {batch_time:.3f}s ({batch_time/len(file_paths)*1000:.1f}ms/æ–‡ä»¶)")
        
        # å°†æ‰¹é‡åˆ†æç»“æœåˆ†é…ç»™æ–‡ä»¶ä¿¡æ¯ï¼Œå¹¶è½¬æ¢æ ¼å¼
        print(f"ğŸ”„ [PERF] è½¬æ¢æ•°æ®æ ¼å¼ä»¥å…¼å®¹ä»»åŠ¡åˆ†é…...")
        format_start = datetime.now()
        
        for file_info in unassigned_files:
            file_path = file_info["path"]
            raw_contributors = batch_contributors.get(file_path, {})
            
            # è½¬æ¢æ•°æ®æ ¼å¼ï¼š{author: count} -> {author: {"score": count, ...}}
            file_contributors = {}
            for author, count in raw_contributors.items():
                if isinstance(count, dict):
                    # å·²ç»æ˜¯æ­£ç¡®æ ¼å¼ï¼ˆåŒ…å«scoreç­‰å­—æ®µï¼‰
                    file_contributors[author] = count
                else:
                    # éœ€è¦è½¬æ¢æ ¼å¼ï¼šç®€å•æ•°å­— -> å®Œæ•´å­—å…¸
                    file_contributors[author] = {
                        "recent_commits": count,
                        "total_commits": count,
                        "score": count
                    }
            
            file_info["contributors"] = file_contributors
        
        format_time = (datetime.now() - format_start).total_seconds()
        print(f"âœ… [PERF] æ•°æ®æ ¼å¼è½¬æ¢å®Œæˆ: {format_time:.3f}s")

        # ç»Ÿè®¡å˜é‡
        assignment_stats = {
            "direct_assignment": 0,
            "directory_fallback": 0,
            "load_balancing": 0,
            "unassigned": 0,
        }

        workload_counter = defaultdict(int)
        assignments = []

        # æ­¥éª¤ 3: æ™ºèƒ½åˆ†é…æ–‡ä»¶
        step3_start = datetime.now()
        tracker.step(f"æ™ºèƒ½åˆ†é… {len(unassigned_files)} ä¸ªæ–‡ä»¶")

        # ä½¿ç”¨è¿›åº¦æŒ‡ç¤ºå™¨å¤„ç†æ–‡ä»¶åˆ†é…ï¼ˆä¸å†éœ€è¦åˆ†æï¼‰
        progress_indicator = ProgressIndicator(f"åˆ†é… {len(unassigned_files)} ä¸ªæ–‡ä»¶")
        progress_indicator.start()

        try:
            for i, file_info in enumerate(unassigned_files):
                file_path = file_info["path"]
                directory = file_info["directory"]

                # æ–‡ä»¶è´¡çŒ®è€…å·²ç»é€šè¿‡æ‰¹é‡åˆ†æè·å¾—
                file_contributors = file_info["contributors"]

                # å°è¯•ç›´æ¥åˆ†é…
                assignee, reason = self._assign_file_to_best_contributor(
                    file_contributors,
                    active_contributors,
                    exclude_authors,
                    workload_counter,
                    max_tasks_per_person,
                )

                if assignee:
                    assignment_stats["direct_assignment"] += 1
                elif include_fallback:
                    # å°è¯•ç›®å½•çº§å›é€€åˆ†é…
                    assignee, reason = self._assign_file_by_directory_fallback(
                        directory,
                        active_contributors,
                        exclude_authors,
                        workload_counter,
                        max_tasks_per_person,
                    )
                    if assignee:
                        assignment_stats["directory_fallback"] += 1
                        reason = f"[ç›®å½•å›é€€] {reason}"

                if assignee:
                    workload_counter[assignee] += 1
                    assignments.append(
                        {"file_path": file_path, "assignee": assignee, "reason": reason}
                    )
                else:
                    assignment_stats["unassigned"] += 1

                # æ¯å¤„ç†50ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if (i + 1) % 50 == 0 or (i + 1) == len(unassigned_files):
                    progress_indicator.update_message(
                        f"å·²åˆ†æ {i + 1}/{len(unassigned_files)} ä¸ªæ–‡ä»¶"
                    )

            progress_indicator.stop(f"æ–‡ä»¶åˆ†æå®Œæˆ")
        except Exception as e:
            progress_indicator.stop(error_message=f"æ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}")
            raise

        step3_time = (datetime.now() - step3_start).total_seconds()
        print(f"â±ï¸  [PERF] æ­¥éª¤3-æ™ºèƒ½åˆ†é…: {step3_time:.3f}s")

        # æ­¥éª¤ 4: æ‰¹é‡åˆ†é…æ–‡ä»¶
        step4_start = datetime.now()
        tracker.step("ä¿å­˜åˆ†é…ç»“æœ")
        assigned_count = self.file_manager.batch_assign_files(assignments)
        
        step4_time = (datetime.now() - step4_start).total_seconds()
        print(f"â±ï¸  [PERF] æ­¥éª¤4-ä¿å­˜åˆ†é…ç»“æœ: {step4_time:.3f}s")

        tracker.finish(f"æ–‡ä»¶ä»»åŠ¡åˆ†é…å®Œæˆï¼ŒæˆåŠŸåˆ†é… {assigned_count} ä¸ªæ–‡ä»¶")

        # æ˜¾ç¤ºåˆ†é…ç»“æœ
        print(f"\nğŸ“Š åˆ†é…ç»“æœè¯¦æƒ…:")
        print(f"   âœ… ç›´æ¥åˆ†é…: {assignment_stats['direct_assignment']} ä¸ªæ–‡ä»¶")
        print(f"   ğŸ”„ ç›®å½•å›é€€: {assignment_stats['directory_fallback']} ä¸ªæ–‡ä»¶")
        print(f"   âš ï¸ æœªåˆ†é…: {assignment_stats['unassigned']} ä¸ªæ–‡ä»¶")

        # æ˜¾ç¤ºå·¥ä½œè´Ÿè½½åˆ†å¸ƒ
        print(f"\nğŸ‘¥ å·¥ä½œè´Ÿè½½åˆ†å¸ƒ:")
        sorted_workload = sorted(
            workload_counter.items(), key=lambda x: x[1], reverse=True
        )
        for assignee, count in sorted_workload[:10]:  # æ˜¾ç¤ºå‰10ä½
            print(f"   {assignee}: {count} ä¸ªæ–‡ä»¶")

        if len(sorted_workload) > 10:
            print(f"   ... è¿˜æœ‰ {len(sorted_workload) - 10} ä½è´¡çŒ®è€…")

        # æ€§èƒ½ç›‘æ§ç»“æŸ
        total_time = (datetime.now() - main_start).total_seconds()
        print(f"âœ… [PERF] æ–‡ä»¶ä»»åŠ¡åˆ†é…æ€»å®Œæˆæ—¶é—´: {total_time:.3f}s")
        print(f"ğŸ“Š [PERF] å¤„ç†ç»Ÿè®¡: æ€»è®¡{total_files}ä¸ªæ–‡ä»¶, å¹³å‡{total_time/total_files*1000:.1f}ms/æ–‡ä»¶")
        
        # ä¿å­˜æ€§èƒ½æ—¥å¿—
        self._save_performance_log(total_files, total_time, {
            'get_contributors': step1_time,
            'batch_analysis': batch_time,
            'format_conversion': format_time,
            'file_assignment': step3_time,
            'save_results': step4_time,
            'mode': 'file_task_assigner'
        })

        return {
            "assigned_count": assigned_count,
            "assignment_stats": assignment_stats,
            "workload_distribution": dict(workload_counter),
            "active_contributors": active_contributors,
            "exclude_authors": exclude_authors,
        }

    def _analyze_file_contributors(self, file_path):
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„è´¡çŒ®è€…"""
        try:
            # è·å–ä¸€å¹´å†…çš„è´¡çŒ®è€…
            one_year_ago = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
            recent_contributors = self.contributor_analyzer.git_ops.get_contributors_since(
                file_path, one_year_ago
            )

            # è·å–æ‰€æœ‰å†å²è´¡çŒ®è€…
            all_contributors = self.contributor_analyzer.git_ops.get_all_contributors(
                file_path
            )

            # åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
            contributors = {}
            for author, recent_count in recent_contributors.items():
                total_count = all_contributors.get(author, recent_count)
                contributors[author] = {
                    "recent_commits": recent_count,
                    "total_commits": total_count,
                    "score": recent_count * 3 + total_count,  # è¿‘æœŸæƒé‡æ›´é«˜
                }

            # æ·»åŠ ä»…æœ‰å†å²è´¡çŒ®çš„ä½œè€…
            for author, total_count in all_contributors.items():
                if author not in contributors:
                    contributors[author] = {
                        "recent_commits": 0,
                        "total_commits": total_count,
                        "score": total_count,
                    }

            return contributors

        except Exception as e:
            print(f"âš ï¸ åˆ†ææ–‡ä»¶ {file_path} è´¡çŒ®è€…æ—¶å‡ºé”™: {e}")
            return {}

    def _assign_file_to_best_contributor(
        self,
        file_contributors,
        active_contributors,
        exclude_authors,
        workload_counter,
        max_tasks_per_person,
    ):
        """å°†æ–‡ä»¶åˆ†é…ç»™æœ€ä½³è´¡çŒ®è€…"""
        if not file_contributors:
            return None, "æ— è´¡çŒ®è€…æ•°æ®"

        # æŒ‰å¾—åˆ†æ’åºè´¡çŒ®è€…
        sorted_contributors = sorted(
            file_contributors.items(), key=lambda x: x[1]["score"], reverse=True
        )

        for author, stats in sorted_contributors:
            # æ£€æŸ¥æ’é™¤æ¡ä»¶
            if author in exclude_authors:
                continue

            # æ£€æŸ¥æ´»è·ƒåº¦
            if author not in active_contributors:
                continue

            # æ£€æŸ¥å·¥ä½œè´Ÿè½½
            if workload_counter[author] >= max_tasks_per_person:
                continue

            # æ‰¾åˆ°åˆé€‚çš„åˆ†é…å¯¹è±¡
            reason = f"æ–‡ä»¶ä¸»è¦è´¡çŒ®è€…(å¾—åˆ†:{stats['score']}, è¿‘æœŸ:{stats['recent_commits']}, å†å²:{stats['total_commits']})"
            return author, reason

        return None, "æ— åˆé€‚çš„æ´»è·ƒè´¡çŒ®è€…"

    def _assign_file_by_directory_fallback(
        self,
        directory,
        active_contributors,
        exclude_authors,
        workload_counter,
        max_tasks_per_person,
    ):
        """åŸºäºç›®å½•åˆ†æè¿›è¡Œå›é€€åˆ†é…"""
        try:
            # åˆ†æç›®å½•çº§è´¡çŒ®è€…
            directory_contributors = self.contributor_analyzer.git_ops.get_directory_contributors(
                directory
            )

            if not directory_contributors:
                return None, "ç›®å½•æ— è´¡çŒ®è€…æ•°æ®"

            # æŒ‰å¾—åˆ†æ’åº
            sorted_contributors = sorted(
                directory_contributors.items(),
                key=lambda x: x[1]["score"],
                reverse=True,
            )

            for author, stats in sorted_contributors:
                # æ£€æŸ¥æ’é™¤æ¡ä»¶
                if author in exclude_authors:
                    continue

                # æ£€æŸ¥æ´»è·ƒåº¦
                if author not in active_contributors:
                    continue

                # æ£€æŸ¥å·¥ä½œè´Ÿè½½
                if workload_counter[author] >= max_tasks_per_person:
                    continue

                # æ‰¾åˆ°åˆé€‚çš„åˆ†é…å¯¹è±¡
                reason = f"ç›®å½•ä¸»è¦è´¡çŒ®è€…(å¾—åˆ†:{stats['score']}, ç›®å½•:{directory})"
                return author, reason

            return None, "ç›®å½•æ— åˆé€‚çš„æ´»è·ƒè´¡çŒ®è€…"

        except Exception as e:
            print(f"âš ï¸ ç›®å½•å›é€€åˆ†é…å¤±è´¥: {e}")
            return None, "ç›®å½•åˆ†æå¤±è´¥"

    def manual_assign_file(self, file_path, assignee, reason="æ‰‹åŠ¨åˆ†é…"):
        """æ‰‹åŠ¨åˆ†é…å•ä¸ªæ–‡ä»¶"""
        success = self.file_manager.assign_file_to_contributor(
            file_path, assignee, reason
        )
        if success:
            print(f"âœ… æ–‡ä»¶ '{file_path}' å·²åˆ†é…ç»™ '{assignee}'")
            print(f"   åŸå› : {reason}")
        else:
            print(f"âŒ åˆ†é…å¤±è´¥: æ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨")

        return success

    def manual_assign_files_batch(self, assignments):
        """æ‰‹åŠ¨æ‰¹é‡åˆ†é…æ–‡ä»¶
        
        Args:
            assignments: List of dict with keys: file_path, assignee, reason
        """
        for assignment in assignments:
            assignment["reason"] = assignment.get("reason", "æ‰‹åŠ¨æ‰¹é‡åˆ†é…")

        assigned_count = self.file_manager.batch_assign_files(assignments)
        print(f"âœ… æ‰¹é‡åˆ†é…å®Œæˆ: {assigned_count} ä¸ªæ–‡ä»¶")

        return assigned_count

    def reassign_files_by_assignee(self, old_assignee, new_assignee, reason="é‡æ–°åˆ†é…"):
        """é‡æ–°åˆ†é…æŒ‡å®šè´Ÿè´£äººçš„æ‰€æœ‰æ–‡ä»¶"""
        files = self.file_manager.get_files_by_assignee(old_assignee)
        if not files:
            print(f"âŒ è´Ÿè´£äºº '{old_assignee}' æ²¡æœ‰åˆ†é…çš„æ–‡ä»¶")
            return 0

        assignments = []
        for file_info in files:
            assignments.append(
                {
                    "file_path": file_info["path"],
                    "assignee": new_assignee,
                    "reason": f"ä» {old_assignee} é‡æ–°åˆ†é…: {reason}",
                }
            )

        assigned_count = self.file_manager.batch_assign_files(assignments)
        print(f"âœ… é‡æ–°åˆ†é…å®Œæˆ: {assigned_count} ä¸ªæ–‡ä»¶ä» '{old_assignee}' è½¬ç»™ '{new_assignee}'")

        return assigned_count

    def balance_workload(self, max_tasks_per_person=50):
        """è´Ÿè½½å‡è¡¡ - é‡æ–°åˆ†é…è¿‡è½½ç”¨æˆ·çš„æ–‡ä»¶"""
        workload = self.file_manager.get_workload_distribution()

        # æ‰¾å‡ºè¿‡è½½çš„ç”¨æˆ·
        overloaded_users = []
        underloaded_users = []

        for assignee, stats in workload.items():
            assigned_count = stats["assigned"]
            if assigned_count > max_tasks_per_person:
                overloaded_users.append(
                    (assignee, assigned_count - max_tasks_per_person)
                )
            elif assigned_count < max_tasks_per_person * 0.7:  # 70%ä»¥ä¸‹è§†ä¸ºè´Ÿè½½ä¸è¶³
                underloaded_users.append(
                    (assignee, max_tasks_per_person - assigned_count)
                )

        if not overloaded_users:
            print("âœ… å½“å‰å·¥ä½œè´Ÿè½½åˆ†å¸ƒåˆç†ï¼Œæ— éœ€è°ƒæ•´")
            return 0

        print(f"ğŸ”„ å‘ç° {len(overloaded_users)} ä¸ªè¿‡è½½ç”¨æˆ·ï¼Œå¼€å§‹è´Ÿè½½å‡è¡¡...")

        reassignments = []
        total_reassigned = 0

        for overloaded_user, excess_count in overloaded_users:
            # è·å–è¯¥ç”¨æˆ·çš„æ–‡ä»¶ï¼ˆæŒ‰ä¼˜å…ˆçº§å’Œåˆ†é…æ—¶é—´æ’åºï¼‰
            user_files = self.file_manager.get_files_by_assignee(overloaded_user)

            # é€‰æ‹©æœ€è¿‘åˆ†é…çš„ã€ä¼˜å…ˆçº§è¾ƒä½çš„æ–‡ä»¶è¿›è¡Œé‡æ–°åˆ†é…
            candidates = sorted(
                [f for f in user_files if f["status"] != "completed"],
                key=lambda x: (
                    x.get("priority", "normal") == "high",
                    x.get("assigned_at", ""),
                ),
                reverse=False,
            )

            files_to_reassign = candidates[:excess_count]

            # åˆ†é…ç»™è´Ÿè½½ä¸è¶³çš„ç”¨æˆ·
            for file_info in files_to_reassign:
                if underloaded_users:
                    target_user, capacity = underloaded_users[0]
                    reassignments.append(
                        {
                            "file_path": file_info["path"],
                            "assignee": target_user,
                            "reason": f"è´Ÿè½½å‡è¡¡: ä» {overloaded_user} è½¬ç§»",
                        }
                    )

                    # æ›´æ–°å®¹é‡
                    underloaded_users[0] = (target_user, capacity - 1)
                    if capacity <= 1:
                        underloaded_users.pop(0)

                    total_reassigned += 1

        if reassignments:
            assigned_count = self.file_manager.batch_assign_files(reassignments)
            print(f"âœ… è´Ÿè½½å‡è¡¡å®Œæˆ: é‡æ–°åˆ†é…äº† {assigned_count} ä¸ªæ–‡ä»¶")
            return assigned_count
        else:
            print("âš ï¸ æ— æ³•æ‰¾åˆ°åˆé€‚çš„é‡æ–°åˆ†é…ç›®æ ‡")
            return 0

    def get_assignment_summary(self):
        """è·å–åˆ†é…æƒ…å†µæ±‡æ€»"""
        file_plan = self.file_manager.load_file_plan()
        if not file_plan:
            return None

        stats = self.file_manager.get_completion_stats()
        workload = self.file_manager.get_workload_distribution()
        directory_summary = self.file_manager.get_directory_summary()

        # åˆ†æåˆ†é…åŸå› ç±»å‹
        reason_stats = defaultdict(int)
        for file_info in file_plan["files"]:
            if file_info.get("assignment_reason"):
                reason = file_info["assignment_reason"]
                if "ç›®å½•å›é€€" in reason:
                    reason_stats["ç›®å½•å›é€€åˆ†é…"] += 1
                elif "æ‰‹åŠ¨" in reason:
                    reason_stats["æ‰‹åŠ¨åˆ†é…"] += 1
                elif "é‡æ–°åˆ†é…" in reason:
                    reason_stats["é‡æ–°åˆ†é…"] += 1
                elif "è´Ÿè½½å‡è¡¡" in reason:
                    reason_stats["è´Ÿè½½å‡è¡¡"] += 1
                else:
                    reason_stats["ç›´æ¥åˆ†é…"] += 1

        return {
            "completion_stats": stats,
            "workload_distribution": workload,
            "directory_summary": directory_summary,
            "assignment_reasons": dict(reason_stats),
            "total_contributors": len(workload),
            "plan_info": {
                "source_branch": file_plan.get("source_branch"),
                "target_branch": file_plan.get("target_branch"),
                "integration_branch": file_plan.get("integration_branch"),
                "created_at": file_plan.get("created_at"),
            },
        }
    
    def _save_performance_log(self, file_count, total_time, step_times):
        """ä¿å­˜æ€§èƒ½æ—¥å¿—åˆ°æ–‡ä»¶"""
        try:
            # è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
            if hasattr(self.contributor_analyzer, 'git_ops') and hasattr(self.contributor_analyzer.git_ops, 'repo_path'):
                repo_path = Path(self.contributor_analyzer.git_ops.repo_path)
            else:
                repo_path = Path(".")
                
            log_file = repo_path / ".merge_work" / "performance_log.json"
            log_file.parent.mkdir(exist_ok=True)
            
            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'file_count': file_count,
                'total_time': total_time,
                'avg_time_per_file': total_time / file_count * 1000,  # ms
                'step_times': step_times,
                'mode': step_times.get('mode', 'file_task_assigner')
            }
            
            # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼ŒåŠ è½½ç°æœ‰æ—¥å¿—
            logs = []
            if log_file.exists():
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        logs = json.load(f)
                except:
                    logs = []
            
            # æ·»åŠ æ–°æ—¥å¿—ï¼ˆä¿ç•™æœ€è¿‘50æ¡ï¼‰
            logs.append(log_entry)
            logs = logs[-50:]
            
            # ä¿å­˜æ—¥å¿—
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“ [PERF] æ€§èƒ½æ—¥å¿—å·²ä¿å­˜: {log_file}")
            
        except Exception as e:
            print(f"âš ï¸ [PERF] ä¿å­˜æ€§èƒ½æ—¥å¿—å¤±è´¥: {e}")
