"""
Git Merge Orchestrator - å¢å¼ºè´¡çŒ®è€…åˆ†ææ¨¡å—ï¼ˆv2.3ï¼‰
è´Ÿè´£ä½¿ç”¨å¤šç»´åº¦æƒé‡ç®—æ³•åˆ†ææ–‡ä»¶å’Œç›®å½•çš„è´¡çŒ®è€…
æ”¯æŒè¡Œæ•°æƒé‡åˆ†æã€æ—¶é—´è¡°å‡æƒé‡ã€ä¸€è‡´æ€§è¯„åˆ†ç­‰é«˜çº§åŠŸèƒ½
"""

from datetime import datetime, timedelta
from config import (
    ENHANCED_CONTRIBUTOR_ANALYSIS,
    ALGORITHM_CONFIGS,
    DEFAULT_ANALYSIS_MONTHS,
    DEFAULT_ACTIVE_MONTHS,
)


class EnhancedContributorAnalyzer:
    """å¢å¼ºè´¡çŒ®è€…åˆ†æå™¨ï¼ˆæ”¯æŒå¤šç»´åº¦æƒé‡ï¼‰"""

    def __init__(self, git_ops):
        self.git_ops = git_ops
        self._active_contributors_cache = None
        self._all_contributors_cache = None
        self.config = ENHANCED_CONTRIBUTOR_ANALYSIS

        # æ£€æŸ¥åŠŸèƒ½æ˜¯å¦å¯ç”¨
        self.enabled = self.config.get("enabled", True)

        if not self.enabled:
            print("âš ï¸  å¢å¼ºè´¡çŒ®è€…åˆ†æå·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€åˆ†æ")

    def is_enabled(self):
        """æ£€æŸ¥å¢å¼ºåˆ†ææ˜¯å¦å¯ç”¨"""
        return self.enabled

    def get_algorithm_config(self):
        """è·å–å½“å‰ç®—æ³•é…ç½®"""
        algorithm_type = self.config.get("assignment_algorithm", "comprehensive")
        return ALGORITHM_CONFIGS.get(algorithm_type, ALGORITHM_CONFIGS["comprehensive"])

    def analyze_file_contributors(
        self, filepath, months=None, enable_line_analysis=True
    ):
        """
        å¢å¼ºæ–‡ä»¶è´¡çŒ®è€…åˆ†æ
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            months: åˆ†ææ—¶é—´èŒƒå›´ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®å€¼ï¼‰
            enable_line_analysis: æ˜¯å¦å¯ç”¨è¡Œæ•°æƒé‡åˆ†æ
            
        Returns:
            dict: å¢å¼ºçš„è´¡çŒ®è€…ä¿¡æ¯
        """
        if not self.enabled:
            # å›é€€åˆ°åŸºç¡€åˆ†æ
            return self._fallback_to_basic_analysis(filepath, months)

        months = months or self.config.get("analysis_months", DEFAULT_ANALYSIS_MONTHS)

        try:
            # ä½¿ç”¨å¢å¼ºGitæ—¥å¿—è§£æ
            contributors = self.git_ops.get_enhanced_file_contributors(
                filepath, months, enable_line_analysis
            )

            # åº”ç”¨æ´»è·ƒåº¦è¿‡æ»¤
            active_contributors = self._filter_active_contributors(contributors)

            # åº”ç”¨æœ€ä½åˆ†æ•°é˜ˆå€¼è¿‡æ»¤
            filtered_contributors = self._apply_score_threshold(active_contributors)

            # æ ‡å‡†åŒ–åˆ†æ•°
            normalized_contributors = self._normalize_scores(filtered_contributors)

            return normalized_contributors

        except Exception as e:
            print(f"å¢å¼ºåˆ†æå¤±è´¥: {e}")
            if self.config.get("fallback_to_simple", True):
                print("å›é€€åˆ°åŸºç¡€åˆ†æ...")
                return self._fallback_to_basic_analysis(filepath, months)
            return {}

    def analyze_contributors_batch(
        self, file_paths, months=None, enable_line_analysis=True
    ):
        """
        æ‰¹é‡å¢å¼ºè´¡çŒ®è€…åˆ†æ
        
        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            months: åˆ†ææ—¶é—´èŒƒå›´
            enable_line_analysis: æ˜¯å¦å¯ç”¨è¡Œæ•°åˆ†æ
            
        Returns:
            dict: {æ–‡ä»¶è·¯å¾„: å¢å¼ºè´¡çŒ®è€…ä¿¡æ¯}
        """
        if not self.enabled:
            return self._fallback_to_basic_batch_analysis(file_paths, months)

        months = months or self.config.get("analysis_months", DEFAULT_ANALYSIS_MONTHS)

        try:
            # ä½¿ç”¨å¢å¼ºæ‰¹é‡Gitæ—¥å¿—è§£æ
            batch_contributors = self.git_ops.get_enhanced_contributors_batch(
                file_paths, months, enable_line_analysis
            )

            # å¯¹æ¯ä¸ªæ–‡ä»¶çš„ç»“æœè¿›è¡Œåå¤„ç†
            processed_results = {}
            for file_path, contributors in batch_contributors.items():
                # åº”ç”¨æ´»è·ƒåº¦è¿‡æ»¤
                active_contributors = self._filter_active_contributors(contributors)

                # åº”ç”¨åˆ†æ•°é˜ˆå€¼è¿‡æ»¤
                filtered_contributors = self._apply_score_threshold(active_contributors)

                # æ ‡å‡†åŒ–åˆ†æ•°
                normalized_contributors = self._normalize_scores(filtered_contributors)

                processed_results[file_path] = normalized_contributors

            return processed_results

        except Exception as e:
            print(f"æ‰¹é‡å¢å¼ºåˆ†æå¤±è´¥: {e}")
            if self.config.get("fallback_to_simple", True):
                print("å›é€€åˆ°åŸºç¡€æ‰¹é‡åˆ†æ...")
                return self._fallback_to_basic_batch_analysis(file_paths, months)
            return {}

    def get_contributor_ranking(self, contributors_dict):
        """
        è·å–è´¡çŒ®è€…æ’å
        
        Args:
            contributors_dict: è´¡çŒ®è€…ä¿¡æ¯å­—å…¸
            
        Returns:
            list: æ’åºåçš„è´¡çŒ®è€…åˆ—è¡¨ [(ä½œè€…, ä¿¡æ¯), ...]
        """
        if not contributors_dict:
            return []

        # æŒ‰å¢å¼ºåˆ†æ•°æ’åº
        sorted_contributors = sorted(
            contributors_dict.items(),
            key=lambda x: x[1].get("enhanced_score", x[1].get("score", 0)),
            reverse=True,
        )

        return sorted_contributors

    def get_best_assignee(self, contributors_dict, exclude_inactive=True):
        """
        è·å–æœ€ä½³ä»»åŠ¡åˆ†é…å¯¹è±¡
        
        Args:
            contributors_dict: è´¡çŒ®è€…ä¿¡æ¯å­—å…¸
            exclude_inactive: æ˜¯å¦æ’é™¤ä¸æ´»è·ƒçš„è´¡çŒ®è€…
            
        Returns:
            tuple: (æœ€ä½³ä½œè€…, ä½œè€…ä¿¡æ¯, æ¨èç†ç”±)
        """
        if not contributors_dict:
            return None, {}, "æ— è´¡çŒ®è€…ä¿¡æ¯"

        # è·å–æ´»è·ƒè´¡çŒ®è€…
        if exclude_inactive:
            active_months = self.config.get("active_months", DEFAULT_ACTIVE_MONTHS)
            active_contributors = self.git_ops.get_active_contributors(active_months)

            # è¿‡æ»¤å‡ºæ´»è·ƒçš„è´¡çŒ®è€…
            filtered_contributors = {
                author: info
                for author, info in contributors_dict.items()
                if author in active_contributors
            }

            if not filtered_contributors:
                # å¦‚æœæ²¡æœ‰æ´»è·ƒè´¡çŒ®è€…ï¼Œä½¿ç”¨æ‰€æœ‰è´¡çŒ®è€…ä½†æ·»åŠ è­¦å‘Š
                filtered_contributors = contributors_dict
                warning_suffix = "ï¼ˆæ³¨æ„ï¼šè¯¥æ–‡ä»¶è¿‘æœŸæ— æ´»è·ƒè´¡çŒ®è€…ï¼‰"
            else:
                warning_suffix = ""
        else:
            filtered_contributors = contributors_dict
            warning_suffix = ""

        # è·å–æœ€é«˜åˆ†è´¡çŒ®è€…
        ranking = self.get_contributor_ranking(filtered_contributors)
        if not ranking:
            return None, {}, "æ— å¯ç”¨è´¡çŒ®è€…"

        best_author, best_info = ranking[0]

        # ç”Ÿæˆæ¨èç†ç”±
        reason = (
            self._generate_assignment_reason(best_author, best_info) + warning_suffix
        )

        return best_author, best_info, reason

    def _filter_active_contributors(self, contributors_dict):
        """è¿‡æ»¤æ´»è·ƒè´¡çŒ®è€…"""
        if not contributors_dict:
            return {}

        active_months = self.config.get("active_months", DEFAULT_ACTIVE_MONTHS)
        active_contributors = self.git_ops.get_active_contributors(active_months)

        # å¦‚æœæ²¡æœ‰æ´»è·ƒè´¡çŒ®è€…ï¼Œè¿”å›åŸå§‹æ•°æ®
        if not active_contributors:
            return contributors_dict

        # è¿‡æ»¤æ´»è·ƒè´¡çŒ®è€…
        filtered = {}
        for author, info in contributors_dict.items():
            if author in active_contributors:
                info["is_active"] = True
                filtered[author] = info
            else:
                # æ ‡è®°ä¸ºä¸æ´»è·ƒä½†ä¿ç•™æ•°æ®
                info["is_active"] = False
                filtered[author] = info

        return filtered

    def _apply_score_threshold(self, contributors_dict):
        """åº”ç”¨æœ€ä½åˆ†æ•°é˜ˆå€¼è¿‡æ»¤"""
        if not contributors_dict:
            return {}

        min_threshold = self.config.get("minimum_score_threshold", 0.1)

        filtered = {}
        for author, info in contributors_dict.items():
            score = info.get("enhanced_score", info.get("score", 0))
            if score >= min_threshold:
                filtered[author] = info

        return filtered if filtered else contributors_dict  # å¦‚æœå…¨éƒ¨è¢«è¿‡æ»¤ï¼Œè¿”å›åŸå§‹æ•°æ®

    def _normalize_scores(self, contributors_dict):
        """æ ‡å‡†åŒ–åˆ†æ•°"""
        if not contributors_dict:
            return {}

        normalization_method = self.config.get("score_normalization", "min_max")

        # æå–æ‰€æœ‰åˆ†æ•°
        scores = []
        for info in contributors_dict.values():
            score = info.get("enhanced_score", info.get("score", 0))
            scores.append(score)

        if not scores:
            return contributors_dict

        # åº”ç”¨æ ‡å‡†åŒ–
        if normalization_method == "min_max":
            min_score = min(scores)
            max_score = max(scores)
            score_range = max_score - min_score

            if score_range == 0:
                return contributors_dict  # æ‰€æœ‰åˆ†æ•°ç›¸åŒï¼Œæ— éœ€æ ‡å‡†åŒ–

            for author, info in contributors_dict.items():
                score = info.get("enhanced_score", info.get("score", 0))
                normalized_score = (score - min_score) / score_range
                info["normalized_score"] = normalized_score

        elif normalization_method == "z_score":
            import statistics

            try:
                mean_score = statistics.mean(scores)
                std_score = statistics.stdev(scores) if len(scores) > 1 else 1

                for author, info in contributors_dict.items():
                    score = info.get("enhanced_score", info.get("score", 0))
                    z_score = (score - mean_score) / std_score if std_score != 0 else 0
                    info["normalized_score"] = z_score
            except statistics.StatisticsError:
                # å›é€€åˆ°åŸå§‹åˆ†æ•°
                for author, info in contributors_dict.items():
                    info["normalized_score"] = info.get(
                        "enhanced_score", info.get("score", 0)
                    )

        elif normalization_method == "percentile":
            import statistics

            sorted_scores = sorted(scores)

            for author, info in contributors_dict.items():
                score = info.get("enhanced_score", info.get("score", 0))
                # è®¡ç®—ç™¾åˆ†ä½æ•°
                percentile = (sorted_scores.index(score) + 1) / len(sorted_scores)
                info["normalized_score"] = percentile

        return contributors_dict

    def _generate_assignment_reason(self, author, author_info):
        """ç”Ÿæˆåˆ†é…æ¨èç†ç”±"""
        reasons = []

        # æå–å…³é”®ä¿¡æ¯
        recent_commits = author_info.get("recent_commits", 0)
        total_commits = author_info.get("total_commits", 0)
        total_changes = author_info.get("total_changes", 0)
        enhanced_score = author_info.get("enhanced_score", 0)

        # åˆ†æ•°è¯¦ç»†ä¿¡æ¯
        score_breakdown = author_info.get("score_breakdown", {})

        # åŸºäºæäº¤æ•°é‡çš„ç†ç”±
        if recent_commits > 0:
            if recent_commits >= 5:
                reasons.append("é«˜é¢‘è¿‘æœŸè´¡çŒ®è€…")
            elif recent_commits >= 2:
                reasons.append("æ´»è·ƒè´¡çŒ®è€…")
            else:
                reasons.append("è¿‘æœŸæœ‰è´¡çŒ®")

        # åŸºäºè¡Œæ•°å˜æ›´çš„ç†ç”±
        if total_changes > 0:
            if total_changes >= 1000:
                reasons.append("å¤§è§„æ¨¡ä»£ç å˜æ›´ç»éªŒ")
            elif total_changes >= 100:
                reasons.append("ä¸­ç­‰è§„æ¨¡å˜æ›´ç»éªŒ")
            else:
                reasons.append("æœ‰ä»£ç å˜æ›´ç»éªŒ")

        # åŸºäºç®—æ³•ç±»å‹çš„ç‰¹æ®Šè¯´æ˜
        algorithm = self.config.get("assignment_algorithm", "comprehensive")
        if algorithm == "comprehensive":
            consistency_score = score_breakdown.get("consistency_score", 0)
            if consistency_score > 0.5:
                reasons.append("æŒç»­è´¡çŒ®æ¨¡å¼")

        # åŸºäºå¢å¼ºè¯„åˆ†çš„æ€»ä½“è¯„ä»·
        if enhanced_score >= 5.0:
            reasons.append("ç»¼åˆè¯„åˆ†ä¼˜ç§€")
        elif enhanced_score >= 2.0:
            reasons.append("ç»¼åˆè¯„åˆ†è‰¯å¥½")

        # ç”Ÿæˆæœ€ç»ˆç†ç”±
        if reasons:
            primary_reason = reasons[0]
            if len(reasons) > 1:
                return f"{primary_reason}ï¼Œ{', '.join(reasons[1:])}"
            return primary_reason

        return "åŸºäºè´¡çŒ®å†å²æ¨è"

    def _fallback_to_basic_analysis(self, filepath, months):
        """å›é€€åˆ°åŸºç¡€åˆ†æ"""
        from .contributor_analyzer import ContributorAnalyzer

        basic_analyzer = ContributorAnalyzer(self.git_ops)
        return basic_analyzer.analyze_file_contributors(filepath)

    def _fallback_to_basic_batch_analysis(self, file_paths, months):
        """å›é€€åˆ°åŸºç¡€æ‰¹é‡åˆ†æ"""
        result = {}
        for file_path in file_paths:
            result[file_path] = self._fallback_to_basic_analysis(file_path, months)
        return result

    def get_analysis_statistics(self, contributors_dict):
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        if not contributors_dict:
            return {}

        stats = {
            "total_contributors": len(contributors_dict),
            "active_contributors": 0,
            "avg_score": 0,
            "max_score": 0,
            "total_commits": 0,
            "total_changes": 0,
            "algorithm_used": self.config.get("assignment_algorithm", "comprehensive"),
        }

        scores = []
        for author, info in contributors_dict.items():
            if info.get("is_active", True):
                stats["active_contributors"] += 1

            score = info.get("enhanced_score", info.get("score", 0))
            scores.append(score)
            stats["max_score"] = max(stats["max_score"], score)
            stats["total_commits"] += info.get("total_commits", 0)
            stats["total_changes"] += info.get("total_changes", 0)

        if scores:
            stats["avg_score"] = sum(scores) / len(scores)

        return stats

    def export_detailed_analysis(self, filepath, contributors_dict, output_file=None):
        """å¯¼å‡ºè¯¦ç»†åˆ†æç»“æœ"""
        if not self.config.get("export_analysis_results", False):
            return False

        import json
        from pathlib import Path

        # å‡†å¤‡å¯¼å‡ºæ•°æ®
        export_data = {
            "file_path": filepath,
            "analysis_timestamp": datetime.now().isoformat(),
            "algorithm_config": self.get_algorithm_config(),
            "contributors": {},
        }

        # å¤„ç†è´¡çŒ®è€…æ•°æ®
        for author, info in contributors_dict.items():
            export_data["contributors"][author] = {
                "basic_info": {
                    "total_commits": info.get("total_commits", 0),
                    "recent_commits": info.get("recent_commits", 0),
                    "total_changes": info.get("total_changes", 0),
                    "is_active": info.get("is_active", True),
                },
                "scoring": info.get("score_breakdown", {}),
                "final_scores": {
                    "enhanced_score": info.get("enhanced_score", 0),
                    "normalized_score": info.get("normalized_score", 0),
                },
            }

        # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
        if not output_file:
            safe_filename = filepath.replace("/", "_").replace(" ", "_")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = (
                f".merge_work/analysis_export_{safe_filename}_{timestamp}.json"
            )

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # å†™å…¥æ–‡ä»¶
        try:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ“Š è¯¦ç»†åˆ†æç»“æœå·²å¯¼å‡º: {output_file}")
            return True

        except Exception as e:
            print(f"å¯¼å‡ºåˆ†æç»“æœå¤±è´¥: {e}")
            return False

    def debug_analysis(self, filepath, contributors_dict):
        """è°ƒè¯•åˆ†æè¿‡ç¨‹ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹å¯ç”¨ï¼‰"""
        if not self.config.get("debug_mode", False):
            return

        print(f"\nğŸ” è°ƒè¯•åˆ†æ: {filepath}")
        print(f"ç®—æ³•ç±»å‹: {self.config.get('assignment_algorithm', 'comprehensive')}")

        for author, info in contributors_dict.items():
            print(f"\nğŸ‘¤ {author}:")
            print(
                f"  åŸºç¡€ä¿¡æ¯: commits={info.get('total_commits', 0)}, changes={info.get('total_changes', 0)}"
            )

            if "score_breakdown" in info:
                breakdown = info["score_breakdown"]
                print(f"  è¯„åˆ†è¯¦æƒ…:")
                for key, value in breakdown.items():
                    print(f"    {key}: {value:.3f}")

            enhanced_score = info.get("enhanced_score", 0)
            normalized_score = info.get("normalized_score", 0)
            print(
                f"  æœ€ç»ˆåˆ†æ•°: enhanced={enhanced_score:.3f}, normalized={normalized_score:.3f}"
            )
