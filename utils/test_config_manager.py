"""
Git Merge Orchestrator - æµ‹è¯•é…ç½®ç®¡ç†å™¨
è´Ÿè´£åŠ è½½å’Œç®¡ç†ç»Ÿä¸€æµ‹è¯•é…ç½®
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass


@dataclass
class TestModeConfig:
    """æµ‹è¯•æ¨¡å¼é…ç½®"""
    description: str
    timeout_seconds: int
    include_categories: List[str]
    parallel_execution: bool
    skip_long_running_tests: bool


@dataclass
class TestCategoryConfig:
    """æµ‹è¯•ç±»åˆ«é…ç½®"""
    description: str
    priority: str
    timeout_seconds: int
    retry_count: int
    tests: List[str]


@dataclass
class ScenarioConfig:
    """åœºæ™¯æµ‹è¯•é…ç½®"""
    description: str
    main_test_category: str
    test_environment_scenarios: List[str]
    expected_duration_seconds: int


class TestConfigManager:
    """æµ‹è¯•é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_file_path: Optional[str] = None):
        """åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨"""
        self.project_root = Path(__file__).parent.parent
        
        if config_file_path:
            self.config_file = Path(config_file_path)
        else:
            self.config_file = self.project_root / "test_config.json"
            
        self._config = None
        self._load_config()
    
    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            if self.config_file.exists():
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self._config = json.load(f)
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                self._config = self._get_default_config()
                print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {self.config_file}")
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
            self._config = self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "test_modes": {
                "quick": {
                    "description": "å¿«é€Ÿæµ‹è¯•æ¨¡å¼",
                    "timeout_seconds": 30,
                    "include_categories": ["health"],
                    "parallel_execution": True,
                    "skip_long_running_tests": True
                },
                "full": {
                    "description": "å®Œæ•´æµ‹è¯•å¥—ä»¶",
                    "timeout_seconds": 900,
                    "include_categories": ["health", "integration", "performance"],
                    "parallel_execution": False,
                    "skip_long_running_tests": False
                }
            },
            "test_categories": {
                "health": {
                    "description": "å¥åº·æ£€æŸ¥æµ‹è¯•",
                    "priority": "high",
                    "timeout_seconds": 60,
                    "retry_count": 1,
                    "tests": ["ä¸»é¡¹ç›®å¥åº·æ£€æŸ¥", "ç¯å¢ƒæ£€æŸ¥"]
                }
            },
            "thresholds": {
                "success_rate": {
                    "excellent": 95.0,
                    "good": 80.0
                }
            }
        }
    
    def get_test_mode_config(self, mode: str) -> Optional[TestModeConfig]:
        """è·å–æµ‹è¯•æ¨¡å¼é…ç½®"""
        mode_data = self._config.get("test_modes", {}).get(mode)
        if not mode_data:
            return None
            
        return TestModeConfig(
            description=mode_data.get("description", ""),
            timeout_seconds=mode_data.get("timeout_seconds", 300),
            include_categories=mode_data.get("include_categories", []),
            parallel_execution=mode_data.get("parallel_execution", False),
            skip_long_running_tests=mode_data.get("skip_long_running_tests", False)
        )
    
    def get_test_category_config(self, category: str) -> Optional[TestCategoryConfig]:
        """è·å–æµ‹è¯•ç±»åˆ«é…ç½®"""
        category_data = self._config.get("test_categories", {}).get(category)
        if not category_data:
            return None
            
        return TestCategoryConfig(
            description=category_data.get("description", ""),
            priority=category_data.get("priority", "medium"),
            timeout_seconds=category_data.get("timeout_seconds", 300),
            retry_count=category_data.get("retry_count", 0),
            tests=category_data.get("tests", [])
        )
    
    def get_scenario_config(self, scenario: str) -> Optional[ScenarioConfig]:
        """è·å–åœºæ™¯é…ç½®"""
        scenario_data = self._config.get("scenario_definitions", {}).get(scenario)
        if not scenario_data:
            return None
            
        return ScenarioConfig(
            description=scenario_data.get("description", ""),
            main_test_category=scenario_data.get("main_test_category", ""),
            test_environment_scenarios=scenario_data.get("test_environment_scenarios", []),
            expected_duration_seconds=scenario_data.get("expected_duration_seconds", 300)
        )
    
    def get_available_test_modes(self) -> List[str]:
        """è·å–å¯ç”¨çš„æµ‹è¯•æ¨¡å¼åˆ—è¡¨"""
        return list(self._config.get("test_modes", {}).keys())
    
    def get_available_test_categories(self) -> List[str]:
        """è·å–å¯ç”¨çš„æµ‹è¯•ç±»åˆ«åˆ—è¡¨"""
        return list(self._config.get("test_categories", {}).keys())
    
    def get_available_scenarios(self) -> List[str]:
        """è·å–å¯ç”¨çš„åœºæ™¯åˆ—è¡¨"""
        return list(self._config.get("scenario_definitions", {}).keys())
    
    def get_success_rate_threshold(self, level: str = "good") -> float:
        """è·å–æˆåŠŸç‡é˜ˆå€¼"""
        return self._config.get("thresholds", {}).get("success_rate", {}).get(level, 80.0)
    
    def get_timeout_for_mode(self, mode: str) -> int:
        """è·å–æµ‹è¯•æ¨¡å¼çš„è¶…æ—¶æ—¶é—´"""
        mode_config = self.get_test_mode_config(mode)
        return mode_config.timeout_seconds if mode_config else 300
    
    def get_environment_config(self, env_name: str) -> Optional[Dict[str, Any]]:
        """è·å–ç¯å¢ƒé…ç½®"""
        return self._config.get("test_environments", {}).get(env_name)
    
    def should_retry_on_failure(self, category: str) -> Tuple[bool, int]:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•å¤±è´¥çš„æµ‹è¯•"""
        category_config = self.get_test_category_config(category)
        if category_config:
            return category_config.retry_count > 0, category_config.retry_count
        
        # é»˜è®¤é‡è¯•é…ç½®
        retry_config = self._config.get("thresholds", {}).get("retry", {})
        max_retries = retry_config.get("max_retries", 0)
        return max_retries > 0, max_retries
    
    def is_parallel_execution_enabled(self, mode: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨å¹¶è¡Œæ‰§è¡Œ"""
        mode_config = self.get_test_mode_config(mode)
        return mode_config.parallel_execution if mode_config else False
    
    def should_skip_long_running_tests(self, mode: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦è·³è¿‡é•¿æ—¶é—´è¿è¡Œçš„æµ‹è¯•"""
        mode_config = self.get_test_mode_config(mode)
        return mode_config.skip_long_running_tests if mode_config else False
    
    def get_reporting_config(self) -> Dict[str, Any]:
        """è·å–æŠ¥å‘Šé…ç½®"""
        return self._config.get("reporting", {
            "formats": ["text"],
            "default_format": "text",
            "include_environment_info": True
        })
    
    def validate_config(self) -> List[str]:
        """éªŒè¯é…ç½®æ–‡ä»¶çš„æœ‰æ•ˆæ€§"""
        issues = []
        
        # æ£€æŸ¥å¿…éœ€çš„èŠ‚
        required_sections = ["test_modes", "test_categories"]
        for section in required_sections:
            if section not in self._config:
                issues.append(f"ç¼ºå°‘å¿…éœ€çš„é…ç½®èŠ‚: {section}")
        
        # æ£€æŸ¥æµ‹è¯•æ¨¡å¼é…ç½®
        test_modes = self._config.get("test_modes", {})
        for mode_name, mode_config in test_modes.items():
            if "include_categories" not in mode_config:
                issues.append(f"æµ‹è¯•æ¨¡å¼ '{mode_name}' ç¼ºå°‘ include_categories é…ç½®")
            
            # æ£€æŸ¥å¼•ç”¨çš„ç±»åˆ«æ˜¯å¦å­˜åœ¨
            categories = mode_config.get("include_categories", [])
            available_categories = self.get_available_test_categories()
            for category in categories:
                if category not in available_categories:
                    issues.append(f"æµ‹è¯•æ¨¡å¼ '{mode_name}' å¼•ç”¨äº†ä¸å­˜åœ¨çš„ç±»åˆ« '{category}'")
        
        # æ£€æŸ¥è¶…æ—¶æ—¶é—´çš„åˆç†æ€§
        for mode_name, mode_config in test_modes.items():
            timeout = mode_config.get("timeout_seconds", 0)
            if timeout <= 0:
                issues.append(f"æµ‹è¯•æ¨¡å¼ '{mode_name}' çš„è¶…æ—¶æ—¶é—´æ— æ•ˆ: {timeout}")
            elif timeout < 10:
                issues.append(f"æµ‹è¯•æ¨¡å¼ '{mode_name}' çš„è¶…æ—¶æ—¶é—´è¿‡çŸ­: {timeout}s")
        
        return issues
    
    def print_config_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("ğŸ“‹ æµ‹è¯•é…ç½®æ‘˜è¦")
        print("=" * 50)
        
        # æµ‹è¯•æ¨¡å¼
        print(f"ğŸ¯ å¯ç”¨æµ‹è¯•æ¨¡å¼: {', '.join(self.get_available_test_modes())}")
        
        # æµ‹è¯•ç±»åˆ«
        print(f"ğŸ“ å¯ç”¨æµ‹è¯•ç±»åˆ«: {', '.join(self.get_available_test_categories())}")
        
        # åœºæ™¯
        scenarios = self.get_available_scenarios()
        if scenarios:
            print(f"ğŸ¬ å¯ç”¨æµ‹è¯•åœºæ™¯: {', '.join(scenarios)}")
        
        # æˆåŠŸç‡é˜ˆå€¼
        thresholds = self._config.get("thresholds", {}).get("success_rate", {})
        print(f"ğŸ“Š æˆåŠŸç‡é˜ˆå€¼: ä¼˜ç§€ {thresholds.get('excellent', 95)}%, è‰¯å¥½ {thresholds.get('good', 80)}%")
        
        # éªŒè¯é…ç½®
        issues = self.validate_config()
        if issues:
            print(f"\nâš ï¸ é…ç½®é—®é¢˜:")
            for issue in issues:
                print(f"   â€¢ {issue}")
        else:
            print(f"\nâœ… é…ç½®éªŒè¯é€šè¿‡")
        
        print("=" * 50)


# å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹
_test_config_manager = None

def get_test_config_manager() -> TestConfigManager:
    """è·å–å…¨å±€æµ‹è¯•é…ç½®ç®¡ç†å™¨å®ä¾‹"""
    global _test_config_manager
    if _test_config_manager is None:
        _test_config_manager = TestConfigManager()
    return _test_config_manager


def main():
    """é…ç½®ç®¡ç†å™¨æµ‹è¯•å‡½æ•°"""
    config_mgr = TestConfigManager()
    config_mgr.print_config_summary()


if __name__ == "__main__":
    main()