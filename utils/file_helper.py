"""
Git Merge Orchestrator - æ–‡ä»¶æ“ä½œå·¥å…·
è´Ÿè´£æ–‡ä»¶ç³»ç»Ÿæ“ä½œã€è·¯å¾„å¤„ç†å’Œæ–‡ä»¶åˆ†ç»„é€»è¾‘
"""

import os
import json
from pathlib import Path
from collections import defaultdict
from datetime import datetime
from config import WORK_DIR_NAME, PLAN_FILE_NAME, GROUP_TYPES


class FileHelper:
    """æ–‡ä»¶æ“ä½œåŠ©æ‰‹ç±»"""

    def __init__(self, repo_path=".", max_files_per_group=5):
        self.repo_path = Path(repo_path)
        self.max_files_per_group = max_files_per_group
        self.work_dir = self.repo_path / WORK_DIR_NAME
        self.work_dir.mkdir(exist_ok=True)

    @property
    def plan_file_path(self):
        """è·å–åˆå¹¶è®¡åˆ’æ–‡ä»¶è·¯å¾„"""
        return self.work_dir / PLAN_FILE_NAME

    def load_plan(self):
        """åŠ è½½åˆå¹¶è®¡åˆ’"""
        if not self.plan_file_path.exists():
            return None

        with open(self.plan_file_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def save_plan(self, plan):
        """ä¿å­˜åˆå¹¶è®¡åˆ’"""
        with open(self.plan_file_path, 'w', encoding='utf-8') as f:
            json.dump(plan, f, indent=2, ensure_ascii=False)

    def create_merge_plan_structure(self, source_branch, target_branch,
                                  integration_branch, changed_files, groups):
        """åˆ›å»ºåˆå¹¶è®¡åˆ’ç»“æ„"""
        return {
            "created_at": datetime.now().isoformat(),
            "source_branch": source_branch,
            "target_branch": target_branch,
            "integration_branch": integration_branch,
            "total_files": len(changed_files),
            "total_groups": len(groups),
            "max_files_per_group": self.max_files_per_group,
            "groups": [
                {
                    "name": group_info["name"],
                    "files": group_info["files"],
                    "file_count": group_info["file_count"],
                    "group_type": group_info["type"],
                    "status": "pending",
                    "assignee": "",
                    "conflicts": [],
                    "notes": "",
                    "contributors": {},
                    "fallback_reason": "",
                    "assignment_reason": ""
                }
                for group_info in groups
            ]
        }

    def iterative_group_files(self, file_paths):
        """è¿­ä»£å¼æ–‡ä»¶åˆ†ç»„ï¼Œé¿å…é€’å½’æ·±åº¦é—®é¢˜"""
        print(f"ğŸ”„ ä½¿ç”¨è¿­ä»£ç®—æ³•å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶...")

        # æŒ‰ç›®å½•å±‚æ¬¡åˆ†ææ–‡ä»¶
        path_analysis = {}
        for file_path in file_paths:
            parts = file_path.split('/')
            depth = len(parts) - 1

            if depth == 0:
                key = "root"
            else:
                key = parts[0]

            if key not in path_analysis:
                path_analysis[key] = []
            path_analysis[key].append(file_path)

        print(f"ğŸ“Š å‘ç° {len(path_analysis)} ä¸ªé¡¶çº§ç›®å½•/åˆ†ç»„")

        groups = []
        for base_path, files in path_analysis.items():
            print(f" å¤„ç† {base_path}: {len(files)} ä¸ªæ–‡ä»¶")

            if len(files) <= self.max_files_per_group:
                groups.append({
                    "name": base_path,
                    "files": files,
                    "file_count": len(files),
                    "type": "simple_group"
                })
            else:
                sub_groups = self._split_large_group(base_path, files)
                groups.extend(sub_groups)

        print(f"âœ… åˆ†ç»„å®Œæˆï¼šå…± {len(groups)} ä¸ªç»„")
        return groups

    def _split_large_group(self, base_path, files):
        """åˆ†å‰²å¤§æ–‡ä»¶ç»„ä¸ºå°ç»„"""
        groups = []

        if base_path == "root":
            return self._split_by_alphabet(base_path, files)

        # éæ ¹ç›®å½•ï¼šå…ˆæŒ‰å­ç›®å½•åˆ†ç»„
        subdir_groups = defaultdict(list)
        direct_files = []

        for file_path in files:
            if file_path.startswith(base_path + "/"):
                relative_path = file_path[len(base_path + "/"):]
                if "/" in relative_path:
                    next_dir = relative_path.split("/")[0]
                    subdir_groups[f"{base_path}/{next_dir}"].append(file_path)
                else:
                    direct_files.append(file_path)
            else:
                direct_files.append(file_path)

        # å¤„ç†ç›´æ¥æ–‡ä»¶
        if direct_files:
            if len(direct_files) <= self.max_files_per_group:
                groups.append({
                    "name": f"{base_path}/direct",
                    "files": direct_files,
                    "file_count": len(direct_files),
                    "type": "direct_files"
                })
            else:
                batch_groups = self._split_into_batches(f"{base_path}/direct", direct_files)
                groups.extend(batch_groups)

        # å¤„ç†å­ç›®å½•
        for subdir_path, subdir_files in subdir_groups.items():
            if len(subdir_files) <= self.max_files_per_group:
                groups.append({
                    "name": subdir_path,
                    "files": subdir_files,
                    "file_count": len(subdir_files),
                    "type": "subdir_group"
                })
            else:
                sub_groups = self._split_large_group(subdir_path, subdir_files)
                groups.extend(sub_groups)

        return groups

    def _split_by_alphabet(self, base_name, files):
        """æŒ‰å­—æ¯åˆ†ç»„æ–‡ä»¶"""
        alpha_groups = defaultdict(list)
        for file_path in files:
            filename = file_path.split('/')[-1]
            first_char = filename[0].lower()

            if first_char.isalpha():
                alpha_groups[first_char].append(file_path)
            elif first_char.isdigit():
                alpha_groups['0-9'].append(file_path)
            else:
                alpha_groups['other'].append(file_path)

        groups = []
        for alpha, alpha_files in alpha_groups.items():
            if len(alpha_files) <= self.max_files_per_group:
                groups.append({
                    "name": f"{base_name}-{alpha}",
                    "files": alpha_files,
                    "file_count": len(alpha_files),
                    "type": "alpha_group"
                })
            else:
                batch_groups = self._split_into_batches(f"{base_name}-{alpha}", alpha_files)
                groups.extend(batch_groups)

        return groups

    def _split_into_batches(self, base_name, files):
        """å°†æ–‡ä»¶åˆ†æ‰¹å¤„ç†"""
        groups = []
        for i in range(0, len(files), self.max_files_per_group):
            batch_files = files[i:i+self.max_files_per_group]
            batch_num = i // self.max_files_per_group + 1
            groups.append({
                "name": f"{base_name}-batch{batch_num}",
                "files": batch_files,
                "file_count": len(batch_files),
                "type": "batch_group"
            })
        return groups

    def create_script_file(self, script_name, script_content):
        """åˆ›å»ºå¹¶ä¿å­˜è„šæœ¬æ–‡ä»¶"""
        script_file = self.work_dir / f"{script_name}.sh"
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(script_content)

        os.chmod(script_file, 0o755)
        return script_file

    def get_group_type_description(self, group_type):
        """è·å–åˆ†ç»„ç±»å‹çš„æè¿°"""
        return GROUP_TYPES.get(group_type, 'æœªçŸ¥ç±»å‹')

    def find_group_by_name(self, plan, group_name):
        """æ ¹æ®ç»„åæŸ¥æ‰¾ç»„"""
        for group in plan["groups"]:
            if group["name"] == group_name:
                return group
        return None

    def get_assignee_groups(self, plan, assignee_name):
        """è·å–æŒ‡å®šè´Ÿè´£äººçš„æ‰€æœ‰ç»„"""
        assignee_groups = []
        for group in plan["groups"]:
            if group.get("assignee", "").lower() == assignee_name.lower():
                assignee_groups.append(group)
        return assignee_groups

    def get_unassigned_groups(self, plan):
        """è·å–æœªåˆ†é…çš„ç»„"""
        return [group for group in plan["groups"] if not group.get("assignee")]

    def get_completed_groups(self, plan):
        """è·å–å·²å®Œæˆçš„ç»„"""
        return [group for group in plan["groups"] if group.get("status") == "completed"]

    def update_group_status(self, plan, group_name, status, completion_time=None):
        """æ›´æ–°ç»„çŠ¶æ€"""
        group = self.find_group_by_name(plan, group_name)
        if group:
            group["status"] = status
            if completion_time:
                group["completed_at"] = completion_time
            return True
        return False

    def get_completion_stats(self, plan):
        """è·å–å®Œæˆç»Ÿè®¡"""
        total_groups = len(plan["groups"])
        assigned_groups = sum(1 for g in plan["groups"] if g.get("assignee"))
        completed_groups = sum(1 for g in plan["groups"] if g.get("status") == "completed")

        total_files = plan["total_files"]
        assigned_files = sum(g.get("file_count", len(g["files"])) for g in plan["groups"] if g.get("assignee"))
        completed_files = sum(g.get("file_count", len(g["files"])) for g in plan["groups"] if g.get("status") == "completed")

        return {
            "total_groups": total_groups,
            "assigned_groups": assigned_groups,
            "completed_groups": completed_groups,
            "total_files": total_files,
            "assigned_files": assigned_files,
            "completed_files": completed_files
        }